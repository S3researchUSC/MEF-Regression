{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ee3b9786",
      "metadata": {
        "id": "ee3b9786"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from pathlib import Path\n",
        "import os\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpae-Nr_ICdX",
        "outputId": "a1352371-faa4-4f35-ed0e-42c1001bee96"
      },
      "id": "mpae-Nr_ICdX",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/MyDrive/NN_MEFs/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzKXANBMILpK",
        "outputId": "e8bbe091-d6f8-420a-aa51-71f4613572ef"
      },
      "id": "EzKXANBMILpK",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " CAISO_Data_2019_2021_NN_Ts.csv   FF_models     MLP_MEFs.ipynb\n",
            "'Experiment notes.gdoc'\t\t  lstm_models   mlp_non_bottleneck_models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5f30fe9",
      "metadata": {
        "id": "a5f30fe9"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "08e1ec4a",
      "metadata": {
        "id": "08e1ec4a"
      },
      "outputs": [],
      "source": [
        "work_dir = \"drive/MyDrive/NN_MEFs\"\n",
        "data_file = f\"{work_dir}/CAISO_Data_2019_2021_NN_Ts.csv\"\n",
        "model_save_dir = f\"{work_dir}/lstm_models\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab3cc09e",
      "metadata": {
        "id": "ab3cc09e"
      },
      "source": [
        "## Data Loading and pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_num_examples_in_block(block_len, seq_len):\n",
        "    return max(block_len - seq_len + 1, 0)\n",
        "\n",
        "def get_num_examples_in_data(block_len, seq_len, total_size):\n",
        "    num_full_blocks = total_size // block_len\n",
        "    block_remainder = total_size % block_len\n",
        "    num_examples = num_full_blocks * get_num_examples_in_block(block_len, seq_len) \\\n",
        "                 + get_num_examples_in_block(block_remainder, seq_len)\n",
        "    return num_examples\n",
        "\n",
        "seq_len = 24\n",
        "block_len = 3 * 24  # chunk data in blocks of 3 days for splitting to train/val/test\n",
        "total_size = 24 * 365 * 3 + 24\n",
        "print(f\"num examples for seq_len=24, block_len=2*24: {get_num_examples_in_data(2*24, 24, total_size)}\")\n",
        "print(f\"num examples for seq_len=24, block_len=3*24: {get_num_examples_in_data(3*24, 24, total_size)}\")\n",
        "print(f\"num examples for seq_len=12, block_len=2*24: {get_num_examples_in_data(2*24, 12, total_size)}\")\n",
        "print(f\"num examples for seq_len=12, block_len=3*24: {get_num_examples_in_data(3*24, 12, total_size)}\")\n",
        "print(f\"num examples for seq_len=3, block_len=2*24: {get_num_examples_in_data(2*24, 3, total_size)}\")\n",
        "print(f\"num examples for seq_len=3, block_len=3*24: {get_num_examples_in_data(3*24, 3, total_size)}\")\n",
        "print(f\"num examples for seq_len=8, block_len=1*24: {get_num_examples_in_data(1*24, 8, total_size)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cClcvOnQaW5q",
        "outputId": "a85f5ad1-a146-4cd3-87ef-94591b7bf065"
      },
      "id": "cClcvOnQaW5q",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num examples for seq_len=24, block_len=2*24: 13700\n",
            "num examples for seq_len=24, block_len=3*24: 17886\n",
            "num examples for seq_len=12, block_len=2*24: 20276\n",
            "num examples for seq_len=12, block_len=3*24: 22278\n",
            "num examples for seq_len=3, block_len=2*24: 25208\n",
            "num examples for seq_len=3, block_len=3*24: 25572\n",
            "num examples for seq_len=8, block_len=1*24: 18632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will try 6:2:2 day-blocks and sequence length of 8 first. "
      ],
      "metadata": {
        "id": "XRzIKschTd9R"
      },
      "id": "XRzIKschTd9R"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "44e7e48e",
      "metadata": {
        "id": "44e7e48e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7867f7b1-7ccb-4fae-d73a-15d3bead6eeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The last block of points assigned is in the val set and has 2.2083333333333335 day(s) of points.\n",
            "number of points in train set: 15251\n",
            "number of points in val set: 5553\n",
            "number of points in test set: 5500\n",
            "\n",
            "After splitting blocks to example sequences:\n",
            "Number of example sequences in train set: 14443 (60.5%)\n",
            "Number of example sequences in val set: 4745 (19.9%)\n",
            "Number of example sequences in test set: 4700 (19.7%)\n"
          ]
        }
      ],
      "source": [
        "# read in the processed data. there should be zero nans or missing data.\n",
        "CAISO_Data = pd.read_csv(data_file, index_col=0)\n",
        "CAISO_Data.index = pd.to_datetime(CAISO_Data.index)\n",
        "\n",
        "# Adding some temporal features\n",
        "CAISO_Data.loc[:,\"Day_of_Year\"] = [instant.timetuple().tm_yday for instant in CAISO_Data.index]\n",
        "\n",
        "num_samples = len(CAISO_Data)\n",
        "\n",
        "# create train, validation and test data\n",
        "data_sets = {\"train\": {\"days_in_block\": 6}, \"val\": {\"days_in_block\": 2}, \"test\": {\"days_in_block\": 2}}\n",
        "seq_len = 8\n",
        "for data in data_sets.values():\n",
        "    data[\"block_len\"] = data[\"days_in_block\"] * 24 + seq_len - 1\n",
        "set_assignments = []\n",
        "remaining_samples_to_assign = num_samples\n",
        "cur_set_idx = 0\n",
        "set_names = list(data_sets.keys())\n",
        "while remaining_samples_to_assign:\n",
        "    cur_set = set_names[cur_set_idx]\n",
        "    samples_to_assign = min(remaining_samples_to_assign, data_sets[cur_set][\"block_len\"])\n",
        "    set_assignments.extend([cur_set for i in range(samples_to_assign)])\n",
        "\n",
        "    cur_set_idx = (cur_set_idx + 1) % len(set_names)\n",
        "    remaining_samples_to_assign -= samples_to_assign\n",
        "\n",
        "set_assignments = np.array(set_assignments)\n",
        "for set_name, data in data_sets.items():\n",
        "    data[\"mask\"] = set_assignments == set_name\n",
        "\n",
        "points_in_last_assignment = 0\n",
        "while set_assignments[-(points_in_last_assignment + 1)] == set_assignments[-1]:\n",
        "    points_in_last_assignment += 1\n",
        "last_assignment_set = set_assignments[-1]\n",
        "print(f\"The last block of points assigned is in the {last_assignment_set} set and has {points_in_last_assignment/24} day(s) of points.\")\n",
        "\n",
        "for set_name, data in data_sets.items():\n",
        "    print(f\"number of points in {set_name} set: {sum(data['mask'])}\")\n",
        "\n",
        "\n",
        "## Specify features to use\n",
        "# feature_cols = ['Load', 'VRE', 'Hour', 'Month', 'Day', 'Pas_Temp', 'SJ_Temp', 'NH_Temp', 'SB_Temp', 'Sac_Temp', 'Fres_Temp', 'LB_Temp']\n",
        "# feature_cols = ['Load', 'VRE', 'Hour', 'Day_of_Year', 'Is_Weekend', 'Pas_Temp', 'SJ_Temp', 'NH_Temp', 'SB_Temp', 'Sac_Temp', 'Fres_Temp', 'LB_Temp']\n",
        "# feature_cols = ['Load', 'VRE', 'Hour', 'Day_of_Year', 'Pas_Temp', 'SJ_Temp', 'NH_Temp', 'SB_Temp', 'Sac_Temp', 'Fres_Temp', 'LB_Temp']\n",
        "# feature_cols.extend([f\"Day_of_Week={day_of_week}\" for day_of_week in range(7)])\n",
        "\n",
        "feature_cols = ['Load', 'VRE', 'Hour', 'Day_of_Year']\n",
        "# feature_cols.extend([f\"Load_t-{i}\" for i in prev_time_steps] + [f\"VRE_t-{i}\" for i in prev_time_steps])\n",
        "# feature_cols.extend([\"Load_d1\", \"Load_d2\", \"VRE_d1\", \"VRE_d2\"])\n",
        "# feature_cols.extend([\"delta_Load\", \"delta_VRE\"])\n",
        "\n",
        "\n",
        "# specify x, bottleneck features, and y data\n",
        "bottleneck_feature_cols = [\"delta_Load\", \"delta_VRE\"]\n",
        "y_col = 'delta_Total_CO2_Emissions'\n",
        "\n",
        "for set_name, data in data_sets.items():\n",
        "    CAISO_subset = CAISO_Data.loc[data[\"mask\"]]\n",
        "    data[\"X\"] = CAISO_subset[feature_cols].values.astype(np.float32)\n",
        "    data[\"y\"] = CAISO_subset[y_col].values.astype(np.float32)\n",
        "    data[\"bottleneck_X\"] = CAISO_subset[bottleneck_feature_cols].values.astype(np.float32)\n",
        "\n",
        "# standardize data based on mean and variance of train data\n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(data_sets[\"train\"][\"X\"])\n",
        "for data in data_sets.values():\n",
        "    data[\"X\"] = scaler.transform(data[\"X\"])\n",
        "\n",
        "# seperate data to contiguous blocks\n",
        "def reshape_to_blocks(arr, block_size):\n",
        "    block_arr = []\n",
        "    start_pos = 0\n",
        "    while start_pos < len(arr):\n",
        "        end = min(start_pos + block_size, len(arr))\n",
        "        block_arr.append(arr[start_pos: end])\n",
        "        start_pos = end\n",
        "    return block_arr\n",
        "\n",
        "def split_blocks_to_seqs(blocks, seq_len=seq_len):\n",
        "    \"\"\"\n",
        "    blocks: num_blocks x block_len [x features]\n",
        "\n",
        "    ret:\n",
        "      seqs: num_seqs x seq_len [x features]\n",
        "    \"\"\"\n",
        "    seqs = []\n",
        "    for block in blocks:\n",
        "        block_len = len(block)\n",
        "        assert block_len >= seq_len\n",
        "        seqs.extend([block[start: start+seq_len] for start in range(block_len - seq_len)])\n",
        "    return np.array(seqs)\n",
        "\n",
        "# split data to contiguous blocks, and expand to example sequences via sliding window over blocks\n",
        "for data in data_sets.values():\n",
        "    for key in [\"X\", \"y\", \"bottleneck_X\"]:\n",
        "        data[key] = reshape_to_blocks(data[key], data[\"block_len\"])\n",
        "        data[key] = split_blocks_to_seqs(data[key], seq_len)\n",
        "        data[key] = torch.tensor(data[key]).to(device)\n",
        "\n",
        "print(f\"\\nAfter splitting blocks to example sequences:\")\n",
        "total_examples = sum(len(data[\"X\"]) for data in data_sets.values())\n",
        "for set_name, data in data_sets.items():\n",
        "    print(f\"Number of example sequences in {set_name} set: {len(data['X'])} ({100*len(data['X'])/total_examples:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_sets[\"train\"][\"y\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMqj3kx1S4Pt",
        "outputId": "ff5ec9a7-f7bf-47f8-91bb-994d214a2f39"
      },
      "id": "jMqj3kx1S4Pt",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14443, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_sets[\"train\"][\"X\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JXpruwnsO7F",
        "outputId": "3394d1d3-34fd-4623-e021-eddc48ec14f2"
      },
      "id": "4JXpruwnsO7F",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14443, 8, 4])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d74d18ea",
      "metadata": {
        "id": "d74d18ea"
      },
      "source": [
        "## define model and set params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7a1f3331",
      "metadata": {
        "id": "7a1f3331"
      },
      "outputs": [],
      "source": [
        "def get_model(n_input, hidden_dim, n_out, dropout_p):\n",
        "    \n",
        "    layers = [nn.lstm(input_size=n_input, hidden_size=hidden_dim,\n",
        "                      batch_first=True, proj_size=n_out, num_layers=1),\n",
        "             ]\n",
        "    \n",
        "    model = nn.Sequential(*layers)\n",
        "    return model\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size,\n",
        "                 final_point_only, num_layers=1, dropout=0, debug=False):\n",
        "        super().__init__()\n",
        "        self.final_point_only = final_point_only\n",
        "        self.debug = debug\n",
        "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
        "                            batch_first=True, num_layers=num_layers, dropout=dropout)\n",
        "        self.batchnorm1d = nn.BatchNorm1d(hidden_size)\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, input_seq):\n",
        "        lstm_out, (hn, cn) = self.lstm(input_seq)\n",
        "        if self.final_point_only:\n",
        "            lstm_out = torch.unsqueeze(lstm_out[:,-1,:], 1) # batch x seq_len x hidden\n",
        "        lstm_out = self.batchnorm1d(lstm_out.permute(0,2,1)) # batch x hidden x seq_len is needed as input\n",
        "        lstm_out = lstm_out.permute(0, 2, 1) # switch hidden and seq_len dims back\n",
        "        # lstm_out = self.dropout(lstm_out)\n",
        "        fc_out = self.fc(lstm_out)\n",
        "        if self.debug:\n",
        "            print(f\"lstm_out: {lstm_out}\")\n",
        "            print(f\"hn: {hn}\")\n",
        "            print(f\"cn: {cn}\")\n",
        "            print(f\"self.fc: {self.fc}\")\n",
        "            print(f\"fc_out: {fc_out}\")\n",
        "        return fc_out\n",
        "\n",
        "def get_y_pred(pred_coeff, bottleneck_X):\n",
        "\n",
        "    MEF_preds = pred_coeff[:,:,0]\n",
        "    MDF_preds = pred_coeff[:,:,1]\n",
        "    delta_load = bottleneck_X[:,:,0]\n",
        "    delta_vre = bottleneck_X[:,:,1]\n",
        "    y_pred_demand = torch.mul(delta_load, MEF_preds)\n",
        "    y_pred_vre = torch.mul(delta_vre, MDF_preds)\n",
        "    y_pred = y_pred_vre + y_pred_demand\n",
        "    if pred_coeff.shape[-1] == 3:\n",
        "        # we are using a linear model with an intercept term\n",
        "        y_pred += pred_coeff[:,:,2]\n",
        "    \n",
        "    return y_pred\n",
        "\n",
        "def mse_loss_l2_coeff_reg(pred_coeff, bottleneck_X, y, MEF_reg_weight, MDF_reg_weight):\n",
        "    \"\"\"\n",
        "    pred_coeff: batch x seq_len x output_dim\n",
        "    bottleneck_X: batch x seq_len x bottleneck_dim\n",
        "    y: batch x seq_len\n",
        "    \"\"\"\n",
        "\n",
        "    y_pred = get_y_pred(pred_coeff, bottleneck_X)\n",
        "\n",
        "    MEF_preds = pred_coeff[:,:,0]\n",
        "    MDF_preds = pred_coeff[:,:,1]\n",
        "\n",
        "    # Compute MEF regularization term (sum(MEF^2 + intercept if MEF < 0 for MEF in examples))\n",
        "    invalid_MEFs = torch.flatten(nn.functional.relu(-MEF_preds))  # keep negative MEFs and zero others\n",
        "    count_invalid_MEFs = torch.count_nonzero(invalid_MEFs)\n",
        "    MEF_reg_intercept = 4420  # based on an average value of -65 seen amongst invalids when trained without regularization\n",
        "    MEF_reg = torch.dot(invalid_MEFs, invalid_MEFs) + (count_invalid_MEFs * MEF_reg_intercept)\n",
        "\n",
        "    # Compute MDF regularization term (sum(MDF^2 + intercept if MDF > 0 for MDF in examples))\n",
        "    invalid_MDFs = torch.flatten(nn.functional.relu(MDF_preds))  # keep negative MEFs and zero others\n",
        "    count_invalid_MDFs = torch.count_nonzero(invalid_MDFs)\n",
        "    MDF_reg_intercept = 538  # based on an average value of +23 seen amongst invalids when trained without regularization\n",
        "    MDF_reg = torch.dot(invalid_MDFs, invalid_MDFs) + (count_invalid_MDFs * MDF_reg_intercept)\n",
        "\n",
        "    loss = nn.MSELoss()(y_pred, y) + (MEF_reg_weight * MEF_reg) + (MDF_reg_weight * MDF_reg)\n",
        "    return loss\n",
        "\n",
        "def mse_loss_l1_coeff_reg(pred_coeff, bottleneck_X, y, MEF_reg_weight, MDF_reg_weight):\n",
        "    \"\"\"\n",
        "    pred_coeff: batch x seq_len x output_dim\n",
        "    bottleneck_X: batch x seq_len x bottleneck_dim\n",
        "    y: batch x seq_len\n",
        "    \"\"\"\n",
        "    y_pred = get_y_pred(pred_coeff, bottleneck_X)\n",
        "\n",
        "    MEF_preds = pred_coeff[:,:,0]\n",
        "    MDF_preds = pred_coeff[:,:,1]\n",
        "\n",
        "    # Compute MEF regularization term (sum(MEF + intercept if MEF < 0 for MEF in examples))\n",
        "    invalid_MEFs = nn.functional.relu(-MEF_preds)  # keep negative MEFs and zero others\n",
        "    count_invalid_MEFs = torch.count_nonzero(invalid_MEFs)\n",
        "    MEF_reg_intercept = 66.5  # The average value seen amongst invalids when trained without regularization\n",
        "    MEF_reg = torch.sum(invalid_MEFs) + (count_invalid_MEFs * MEF_reg_intercept)\n",
        "\n",
        "    # Compute MDF regularization term (sum(MDF + intercept if MDF > 0 for MDF in examples))\n",
        "    invalid_MDFs = nn.functional.relu(MDF_preds)  # keep negative MEFs and zero others\n",
        "    count_invalid_MDFs = torch.count_nonzero(invalid_MDFs)\n",
        "    MDF_reg_intercept = 23.2  # The average value seen amongst invalids when trained without regularization\n",
        "    MDF_reg = torch.sum(invalid_MDFs) + (count_invalid_MDFs * MDF_reg_intercept)\n",
        "\n",
        "    loss = nn.MSELoss()(y_pred, y) + (MEF_reg_weight * MEF_reg) + (MDF_reg_weight * MDF_reg)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a1bc93f",
      "metadata": {
        "id": "0a1bc93f"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2daa481",
      "metadata": {
        "id": "f2daa481"
      },
      "source": [
        "Helpers for printing results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e34e76b6",
      "metadata": {
        "id": "e34e76b6"
      },
      "outputs": [],
      "source": [
        "pd.options.mode.chained_assignment = None  # default='warn'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "738cbf27",
      "metadata": {
        "id": "738cbf27"
      },
      "outputs": [],
      "source": [
        "def plot_losses(train_losses, val_losses, plt_save_dir=None):\n",
        "    # plot loss vs epochs\n",
        "    fig, axs = plt.subplots(1,2)\n",
        "    axs[0].plot(train_losses[50:])\n",
        "    axs[0].set_title(\"Train Set\")\n",
        "    axs[0].set_ylabel('loss')\n",
        "    axs[0].set_xlabel('epoch')\n",
        "\n",
        "    axs[1].plot(val_losses[50:])\n",
        "    axs[1].set_title(\"Val Set\")\n",
        "    axs[1].set_ylabel('loss')\n",
        "    axs[1].set_xlabel('epoch')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    if plt_save_dir:\n",
        "        fig.savefig(f\"{plt_save_dir}/train_val_losses.png\") \n",
        "\n",
        "# Probably delete this\n",
        "# def print_results(train_losses, train_pred_coeff, train_bottleneck_X, train_y,\n",
        "#                   val_losses, val_pred_coeff, val_bottleneck_X, val_y, \n",
        "#                   plt_save_dir=None):\n",
        "#     # plot loss vs epochs\n",
        "#     fig, axs = plt.subplots(1,2)\n",
        "#     axs[0].plot(train_losses[1:])\n",
        "#     axs[0].set_title(\"Train Set\")\n",
        "#     axs[0].set_ylabel('loss')\n",
        "#     axs[0].set_xlabel('epoch')\n",
        "\n",
        "#     axs[1].plot(val_losses[1:])\n",
        "#     axs[1].set_title(\"Val Set\")\n",
        "#     axs[1].set_ylabel('loss')\n",
        "#     axs[1].set_xlabel('epoch')\n",
        "    \n",
        "#     plt.tight_layout()\n",
        "#     plt.show()\n",
        "    \n",
        "#     if plt_save_dir:\n",
        "#         fig.savefig(f\"{plt_save_dir}/train_val_losses.png\") \n",
        "\n",
        "#     train_y_pred = get_y_pred(train_pred_coeff, train_bottleneck_X)\n",
        "#     val_y_pred = get_y_pred(val_pred_coeff, val_bottleneck_X)\n",
        "\n",
        "#     # count number of invalid values predicted\n",
        "#     invalid_train_MEFs, invalid_train_MDFs = get_count_invalid_preds(train_pred_coeff)\n",
        "#     invalid_val_MEFs, invalid_val_MDFs = get_count_invalid_preds(val_pred_coeff)\n",
        "\n",
        "#     # calculate performance metrics\n",
        "#     train_error = train_y_pred - train_y\n",
        "#     print(\"Train Set:\")\n",
        "#     print(f\"\\tMean Emissions Change = {torch.mean(torch.abs(train_y)).item():.2f}\")\n",
        "#     print(f\"\\tMean Error = {torch.mean(torch.abs(train_error)).item():.2f}\")\n",
        "#     print(f\"\\tInvalid MEFs,MDFs = {invalid_train_MEFs},{invalid_train_MDFs}\")\n",
        "#     print(f\"\\tR Squared = {r2_score(train_y.cpu().detach().numpy(), train_y_pred.cpu().detach().numpy()):.4f}\")\n",
        "    \n",
        "#     val_error = val_y_pred - val_y\n",
        "#     print(\"Val Set:\")\n",
        "#     print(f\"\\tMean Emissions Change = {torch.mean(torch.abs(val_y)).item():.2f}\")\n",
        "#     print(f\"\\tMean Error = {torch.mean(torch.abs(val_error)).item():.2f}\")\n",
        "#     print(f\"\\tInvalid MEFs,MDFs = {invalid_val_MEFs},{invalid_val_MDFs}\")\n",
        "#     print(f\"\\tR Squared = {r2_score(val_y.cpu().detach().numpy(), val_y_pred.cpu().detach().numpy()):.4f}\")\n",
        "    \n",
        "def get_r_squared(pred_coeff, bottleneck_X, y):\n",
        "    y_pred = get_y_pred(pred_coeff, bottleneck_X)\n",
        "    # only one element in sequence is being predicted, return single R2\n",
        "    if y.shape[-1] == 1:\n",
        "        return r2_score(y.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
        "    # more than one elt in seq being predicted, return an R2 for each position that we could evaluate at\n",
        "    else:\n",
        "        return [r2_score(y_i, y_pred_i) for y_i, y_pred_i in \\\n",
        "                zip(y.permute(1,0).cpu().detach().numpy(),\n",
        "                    y_pred.permute(1,0).cpu().detach().numpy())]\n",
        "\n",
        "def get_mean_abs_err(pred_coeff, bottleneck_X, y):\n",
        "    y_pred = get_y_pred(pred_coeff, bottleneck_X)\n",
        "    # only one element in sequence is being predicted, return single MAE\n",
        "    if y.shape[-1] == 1:\n",
        "        return mean_absolute_error(y.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
        "    # more than one elt in seq being predicted, return an MAE for each position that we could evaluate at\n",
        "    else:\n",
        "        return [mean_absolute_error(y_i, y_pred_i) for y_i, y_pred_i in \\\n",
        "                zip(y.permute(1,0).cpu().detach().numpy(),\n",
        "                    y_pred.permute(1,0).cpu().detach().numpy())]\n",
        "\n",
        "def get_count_invalid_preds(pred_coeff):\n",
        "    count_neg_MEFs = torch.sum(pred_coeff[:,:,0] <= 0).item()  # MEF must be greater than 0\n",
        "    count_pos_MDFs = torch.sum(pred_coeff[:,:,1] > 0).item()  # MDF must be less than or equal to 0\n",
        "    return count_neg_MEFs, count_pos_MDFs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9df07382",
      "metadata": {
        "id": "9df07382"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_with_params_batched(train_X, val_X, train_bottleneck_X, val_bottleneck_X, train_y, val_y,  # data\n",
        "                            input_size, hidden_size, output_size, final_point_only, num_layers, dropout,  # model settings\n",
        "                            learning_rate, weight_decay,  # optimizer settings\n",
        "                            loss_function, MEF_reg_weight, MDF_reg_weight,  # loss function settings\n",
        "                            model_dir_prefix=None, batch_size=None, epochs=10000, # train process settings\n",
        "                            print_freq=1000, min_save_r2=.87, max_save_mae=150000):  # train process settings\n",
        "\n",
        "    if not batch_size:\n",
        "        batch_size = len(train_X)\n",
        "\n",
        "    # if predicting final point in sequence only, keep only those corresponding points\n",
        "    # in the bottleneck_X and y arrays\n",
        "    if final_point_only:\n",
        "        train_bottleneck_X = torch.unsqueeze(train_bottleneck_X[:,-1,:], 1)\n",
        "        val_bottleneck_X = torch.unsqueeze(val_bottleneck_X[:,-1,:], 1)\n",
        "        train_y = torch.unsqueeze(train_y[:,-1], 1)\n",
        "        val_y = torch.unsqueeze(val_y[:,-1], 1)\n",
        "\n",
        "    # create model and optimizer\n",
        "    model = LSTM(input_size, hidden_size, output_size, final_point_only, num_layers, dropout)\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Set up folder where model and model info will be saved\n",
        "    model_dir = model_save_dir\n",
        "    if model_dir_prefix:\n",
        "        model_dir += f\"/{model_dir_prefix}\"\n",
        "    model_dir += f\"/{datetime.now().strftime('%Y_%m_%d-%I:%M:%S_%p')}\"\n",
        "    Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # log experiment settings\n",
        "    settings_str = \"Model Settings:\"\n",
        "    settings_str += f\"\\n\\t{input_size=}\\n\\t{hidden_size=}\\n\\t{output_size=}\\n\\t{final_point_only=}\\n\\t{num_layers=}\\n\\t{dropout=}\"\n",
        "    settings_str += \"\\nOptimizer Settings:\"\n",
        "    settings_str += f\"\\n\\t{learning_rate=}\\n\\t{weight_decay=}\"\n",
        "    settings_str += \"\\nLoss Function Settings:\"\n",
        "    settings_str += f\"\\n\\t{loss_function=}\\n\\t{MEF_reg_weight=}\\n\\t{MDF_reg_weight=}\"\n",
        "    settings_str += \"\\nTrain Process Settings:\"\n",
        "    settings_str += f\"\\n\\t{batch_size=}\\n\\t{epochs=}\\n\\t{min_save_r2=}\\n\\t{max_save_mae=}\"\n",
        "    settings_str += f\"\\nFeatures: {', '.join(feature_cols)}\"\n",
        "    print(settings_str)\n",
        "    with open(f\"{model_dir}/experiment_settings.txt\", 'w+') as f:\n",
        "        f.write(settings_str)\n",
        "\n",
        "    # set up vars for keeping track of stats of best-seen models\n",
        "    best_r2 = -np.inf\n",
        "    best_r2_epoch = None\n",
        "    best_mae = np.inf\n",
        "    best_mae_epoch = None\n",
        "    best_r2_model = {\"r2\": -np.inf}\n",
        "    best_mae_model = {\"mae\": np.inf}\n",
        "    if not final_point_only:\n",
        "        best_r2_any_point = -np.inf\n",
        "        best_r2_any_point_list = None\n",
        "        best_mae_any_point = np.inf\n",
        "        best_mae_any_point_list = None\n",
        "    \n",
        "    # train/eval loop\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    batches_per_epoch = int(np.ceil(len(train_X) / batch_size))\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        if batches_per_epoch > 1:\n",
        "            shuffle_perm = torch.randperm(len(train_X))\n",
        "            train_X = train_X[shuffle_perm]\n",
        "            train_bottleneck_X = train_bottleneck_X[shuffle_perm]\n",
        "            train_y = train_y[shuffle_perm]\n",
        "\n",
        "        # tell model we are training\n",
        "        model.train()\n",
        "        # make updates based on each batch in training data\n",
        "        for batch in range(batches_per_epoch):\n",
        "            batch_start, batch_end = batch * batch_size, (batch + 1) * batch_size\n",
        "            batch_train_X = train_X[batch_start: batch_end]\n",
        "            batch_train_bottleneck_X = train_bottleneck_X[batch_start: batch_end]\n",
        "            batch_train_y = train_y[batch_start: batch_end]\n",
        "        \n",
        "            batch_train_pred_coeff = model(batch_train_X.float())\n",
        "            batch_train_loss = loss_function(batch_train_pred_coeff, batch_train_bottleneck_X, batch_train_y, MEF_reg_weight, MDF_reg_weight)\n",
        "            model.zero_grad()\n",
        "            batch_train_loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "        # tell model we are evaluating\n",
        "        model.eval()\n",
        "\n",
        "        # re-run on training data to get current train loss for the epoch\n",
        "        train_pred_coeff = model(train_X.float())\n",
        "        train_loss = loss_function(train_pred_coeff, train_bottleneck_X, train_y, MEF_reg_weight, MDF_reg_weight)\n",
        "        train_losses.append(train_loss.item())\n",
        "\n",
        "        # run on val data to evaluate how we are doing\n",
        "        val_pred_coeff = model(val_X.float())\n",
        "        val_loss = loss_function(val_pred_coeff, val_bottleneck_X, val_y, MEF_reg_weight, MDF_reg_weight)\n",
        "        val_losses.append(val_loss.item())\n",
        "        val_r2 = get_r_squared(val_pred_coeff, val_bottleneck_X, val_y)\n",
        "        val_mae = get_mean_abs_err(val_pred_coeff, val_bottleneck_X, val_y)\n",
        "        if not final_point_only:\n",
        "            val_r2_list = val_r2\n",
        "            val_mae_list = val_mae\n",
        "            # evaluate on last point in sequence only\n",
        "            val_r2 = val_r2[-1] \n",
        "            val_mae = val_mae[-1]\n",
        "            # update best seen at any point in sequence\n",
        "            val_r2_any_point = max(val_r2_list)\n",
        "            if val_r2_any_point > best_r2_any_point:\n",
        "                best_r2_any_point = val_r2_any_point\n",
        "                best_r2_any_point_list = val_r2_list\n",
        "            val_mae_any_point = min(val_mae_list) \n",
        "            if val_mae_any_point < best_mae_any_point:\n",
        "                best_mae_any_point = val_mae_any_point\n",
        "                best_mae_any_point_list = val_mae_list\n",
        "\n",
        "        # always keep best r2 and mae updated\n",
        "        if val_r2 > best_r2:\n",
        "            best_r2 = val_r2\n",
        "            best_r2_epoch = epoch\n",
        "        if val_mae < best_mae:\n",
        "            best_mae = val_mae\n",
        "            best_mae_epoch = epoch\n",
        "\n",
        "        # check if we should save best r2 model\n",
        "        if val_r2 > max(best_r2_model[\"r2\"], min_save_r2):\n",
        "            # only continue with saving if this model has no invalids\n",
        "            if sum(get_count_invalid_preds(val_pred_coeff))==0 and sum(get_count_invalid_preds(train_pred_coeff))==0:\n",
        "                # update best-r2-model stats\n",
        "                best_r2_model[\"r2\"] = val_r2\n",
        "                best_r2_model[\"epoch\"] = epoch\n",
        "                best_r2_model[\"mae\"] = val_mae\n",
        "                if not final_point_only:\n",
        "                    best_r2_model[\"seq-wise-r2\"] = val_r2_list\n",
        "                    best_r2_model[\"seq-wise-mae\"] = val_mae_list\n",
        "                # delete prev best-r2-model unless best-mae-model still points to it\n",
        "                if \"save_path\" in best_r2_model \\\n",
        "                and (\"save_path\" not in best_mae_model \\\n",
        "                or best_r2_model[\"save_path\"] != best_mae_model[\"save_path\"]):\n",
        "                    Path(best_r2_model[\"save_path\"]).unlink() # delete prev-best model\n",
        "                model_save_name = f\"epoch={epoch},r2={val_r2:.4f},mae={int(val_mae)},Invalids=0.pth\"\n",
        "                save_model_path = f\"{model_dir}/{model_save_name}\"\n",
        "                best_r2_model[\"save_path\"] = save_model_path\n",
        "                torch.save(model.state_dict(), save_model_path)\n",
        "\n",
        "        # check if we should save best mae model\n",
        "        if val_mae < min(best_mae_model[\"mae\"], max_save_mae):\n",
        "            # if we already saved best-r2-model on this round, then that model is our best mae model\n",
        "            if epoch in best_r2_model and best_r2_model[\"epoch\"] == epoch:\n",
        "                best_mae_model[\"r2\"] = val_r2\n",
        "                best_mae_model[\"epoch\"] = epoch\n",
        "                best_mae_model[\"mae\"] = val_mae\n",
        "                if not final_point_only:\n",
        "                    best_mae_model[\"seq-wise-r2\"] = val_r2_list\n",
        "                    best_mae_model[\"seq-wise-mae\"] = val_mae_list\n",
        "                # delete prev best-mae-model\n",
        "                if \"save_path\" in best_mae_model:\n",
        "                    Path(best_mae_model[\"save_path\"]).unlink() # delete prev-best model\n",
        "                best_mae_model[\"save_path\"] = best_r2_model[\"save_path\"]\n",
        "            # Otherwise need to check again if this model has no invalids\n",
        "            elif sum(get_count_invalid_preds(val_pred_coeff))==0 and sum(get_count_invalid_preds(train_pred_coeff))==0:\n",
        "                # update best-mae-model stats\n",
        "                best_mae_model[\"r2\"] = val_r2\n",
        "                best_mae_model[\"epoch\"] = epoch\n",
        "                best_mae_model[\"mae\"] = val_mae\n",
        "                if not final_point_only:\n",
        "                    best_mae_model[\"seq-wise-r2\"] = val_r2_list\n",
        "                    best_mae_model[\"seq-wise-mae\"] = val_mae_list\n",
        "                # delete prev best-mae-model unless best-r2-model still points to it\n",
        "                if \"save_path\" in best_mae_model \\\n",
        "                and (\"save_path\" not in best_r2_model \\\n",
        "                or best_r2_model[\"save_path\"] != best_mae_model[\"save_path\"]):\n",
        "                    Path(best_mae_model[\"save_path\"]).unlink() # delete prev-best model\n",
        "                model_save_name = f\"epoch={epoch},r2={val_r2:.4f},mae={int(val_mae)},Invalids=0.pth\"\n",
        "                save_model_path = f\"{model_dir}/{model_save_name}\"\n",
        "                best_mae_model[\"save_path\"] = save_model_path\n",
        "                torch.save(model.state_dict(), save_model_path)\n",
        "\n",
        "        # print performance info every so often\n",
        "        if epoch % print_freq == 0:\n",
        "            invalid_train_MEFs, invalid_train_MDFs = get_count_invalid_preds(train_pred_coeff)\n",
        "            invalid_val_MEFs, invalid_val_MDFs = get_count_invalid_preds(val_pred_coeff)\n",
        "            train_r2 = get_r_squared(train_pred_coeff, train_bottleneck_X, train_y)\n",
        "            if not final_point_only:\n",
        "                # evaluate on last point in sequence only\n",
        "                train_r2 = train_r2[-1] \n",
        "            print(f\"[Epoch {epoch}]\")\n",
        "            print(f\"\\tTrain Set: Loss={train_loss.item():.3e}, R Squared={train_r2:.4f}, Invalid MEFs={invalid_train_MEFs}, Invalid MDFs={invalid_train_MDFs}\")\n",
        "            print(f\"\\tVal Set: Loss={val_loss.item():.3e}, R Squared={val_r2:.4f}, Invalid MEFs={invalid_val_MEFs}, Invalid MDFs={invalid_val_MDFs}\")\n",
        "\n",
        "        # stop if we aren't improving after 10k epochs\n",
        "        if best_r2_epoch and epoch > 10000 + best_r2_epoch:\n",
        "            print(\"Early stopping as we haven't made an improvement on validation set in 10,000 epochs.\")\n",
        "            break\n",
        "    \n",
        "    plot_losses(train_losses, val_losses, model_dir)\n",
        "\n",
        "    results_str = f\"Best R Squared seen on epoch {best_r2_epoch}: {best_r2:.4f}\"\n",
        "    results_str += f\"\\nBest MAE seen on epoch {best_mae_epoch}: {best_mae:.2f}\"\n",
        "    results_str += f\"\\nBest-R2-model with R2 above {min_save_r2=} and 0 invalid coefficients predicted on train/test sets:\"\n",
        "    if \"save_path\" not in best_r2_model:\n",
        "        results_str += f\"\\n\\tNo such model was encountered\"\n",
        "    else:\n",
        "        results_str += f\"\\n\\tValidation R2: {best_r2_model['r2']:.4f}\"\n",
        "        results_str += f\"\\n\\tValidation MAE: {best_r2_model['mae']:.2f}\"\n",
        "        if not final_point_only:\n",
        "            r2_str_list = [f\"{val:.4f}\" for val in best_r2_model['seq-wise-r2']]\n",
        "            results_str += f\"\\n\\tValidation sequence-wise-R2: {r2_str_list}\"\n",
        "            mae_str_list = [f\"{val:.2f}\" for val in best_r2_model['seq-wise-mae']]\n",
        "            results_str += f\"\\n\\tValidation sequence-wise-MAE: {mae_str_list}\"\n",
        "        results_str += f\"\\n\\tEpoch seen: {best_r2_model['epoch']}\"\n",
        "        results_str += f\"\\n\\tModel file: {best_r2_model['save_path'].split('/')[-1]}\"\n",
        "    results_str += f\"\\nBest-MAE-model with MAE below {max_save_mae=} and 0 invalid coefficients predicted on train/test sets:\"\n",
        "    if \"save_path\" not in best_mae_model:\n",
        "        results_str += f\"\\n\\tNo such model was encountered\"\n",
        "    else:\n",
        "        results_str += f\"\\n\\tValidation R2: {best_mae_model['r2']:.4f}\"\n",
        "        results_str += f\"\\n\\tValidation MAE: {best_mae_model['mae']:.2f}\"\n",
        "        if not final_point_only:\n",
        "            r2_str_list = [f\"{val:.4f}\" for val in best_mae_model['seq-wise-r2']]\n",
        "            results_str += f\"\\n\\tValidation sequence-wise-R2: {r2_str_list}\"\n",
        "            mae_str_list = [f\"{val:.2f}\" for val in best_mae_model['seq-wise-mae']]\n",
        "            results_str += f\"\\n\\tValidation sequence-wise-MAE: {mae_str_list}\"\n",
        "        results_str += f\"\\n\\tEpoch seen: {best_mae_model['epoch']}\"\n",
        "        results_str += f\"\\n\\tModel file: {best_mae_model['save_path'].split('/')[-1]}\"\n",
        "    if not final_point_only:\n",
        "        results_str += f\"\\nSequence-wise-R2 with the highest R2 at any point in the sequence of {best_r2_any_point:.4f}:\"\n",
        "        r2_str_list = [f\"{val:.4f}\" for val in best_r2_any_point_list]\n",
        "        results_str += f\"\\n\\t{r2_str_list}\"\n",
        "        results_str += f\"\\nSequence-wise-MAE with the lowest MAE at any point in the sequence of {best_mae_any_point:.2f}:\"\n",
        "        mae_str_list = [f\"{val:.2f}\" for val in best_mae_any_point_list]\n",
        "        results_str += f\"\\n\\t{mae_str_list}\"\n",
        "\n",
        "    print(results_str)\n",
        "    with open(f\"{model_dir}/results.txt\", 'w+') as f:\n",
        "        f.write(results_str)\n",
        "\n",
        "\n",
        "    "
      ],
      "metadata": {
        "id": "R23-ZIyRwanX"
      },
      "id": "R23-ZIyRwanX",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "id": "084cdb90",
      "metadata": {
        "id": "084cdb90"
      },
      "outputs": [],
      "source": [
        "def train_model_with_params(train_X, val_X, train_bottleneck_X, val_bottleneck_X, train_y, val_y,  # data\n",
        "                            input_size, hidden_size, output_size, final_point_only, num_layers, dropout,  # model settings\n",
        "                            learning_rate, weight_decay,  # optimizer settings\n",
        "                            loss_function, MEF_reg_weight, MDF_reg_weight,  # loss function settings\n",
        "                            model_dir_prefix=None, epochs=10000, print_freq=1000, min_save_r2=.87):  # train process settings\n",
        "\n",
        "    # if predicting final point in sequence only, keep only those corresponding points\n",
        "    # in the bottleneck_X and y arrays\n",
        "    if final_point_only:\n",
        "        train_bottleneck_X = torch.unsqueeze(train_bottleneck_X[:,-1,:], 1)\n",
        "        val_bottleneck_X = torch.unsqueeze(val_bottleneck_X[:,-1,:], 1)\n",
        "        train_y = torch.unsqueeze(train_y[:,-1], 1)\n",
        "        val_y = torch.unsqueeze(val_y[:,-1], 1)\n",
        "\n",
        "    # create model and optimizer\n",
        "    model = LSTM(input_size, hidden_size, output_size, final_point_only, num_layers, dropout)\n",
        "    model.to(device)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "    # Set up folder where model and model info will be saved\n",
        "    model_dir = model_save_dir\n",
        "    if model_dir_prefix:\n",
        "        model_dir += f\"/{model_dir_prefix}\"\n",
        "    model_dir += f\"/{datetime.now().strftime('%Y_%m_%d-%I:%M:%S_%p')}\"\n",
        "    Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # log experiment settings\n",
        "    settings_str = \"Model Settings:\"\n",
        "    settings_str += f\"\\n\\t{input_size=}\\n\\t{hidden_size=}\\n\\t{output_size=}\\n\\t{final_point_only=}\\n\\t{num_layers=}\\n\\t{dropout=}\"\n",
        "    settings_str += \"\\nOptimizer Settings:\"\n",
        "    settings_str += f\"\\n\\t{learning_rate=}\\n\\t{weight_decay=}\"\n",
        "    settings_str += \"\\nLoss Function Settings:\"\n",
        "    settings_str += f\"\\n\\t{loss_function=}\\n\\t{MEF_reg_weight=}\\n\\t{MDF_reg_weight=}\"\n",
        "    settings_str += \"\\nTrain Process Settings:\"\n",
        "    settings_str += f\"\\n\\t{epochs=}\\n\\t{min_save_r2=}\"\n",
        "    settings_str += f\"\\nFeatures: {', '.join(feature_cols)}\"\n",
        "    print(settings_str)\n",
        "    with open(f\"{model_dir}/experiment_settings.txt\", 'w+') as f:\n",
        "        f.write(settings_str)\n",
        "\n",
        "    best_r2 = -np.inf \n",
        "    best_epoch = None\n",
        "    best_model_mae = -np.inf\n",
        "    save_model_path = None\n",
        "    last_save_epoch = None\n",
        "    last_save_r2 = -np.inf\n",
        "    \n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        # tell model we are training\n",
        "        model.train()\n",
        "        train_pred_coeff = model(train_X.float())\n",
        "        train_loss = loss_function(train_pred_coeff, train_bottleneck_X, train_y, MEF_reg_weight, MDF_reg_weight)\n",
        "        train_losses.append(train_loss.item())\n",
        "        \n",
        "        # tell model we are evaluating\n",
        "        model.eval()\n",
        "        val_pred_coeff = model(val_X.float())\n",
        "        val_loss = loss_function(val_pred_coeff, val_bottleneck_X, val_y, MEF_reg_weight, MDF_reg_weight)\n",
        "        val_losses.append(val_loss.item())\n",
        "        val_r2 = get_r_squared(val_pred_coeff, val_bottleneck_X, val_y)\n",
        "\n",
        "        # always keep best r2 updated\n",
        "        if val_r2 > best_r2:\n",
        "            best_r2 = val_r2\n",
        "            best_model_mae = get_mean_abs_err(val_pred_coeff, val_bottleneck_X, val_y)\n",
        "            best_epoch = epoch\n",
        "        # check if we should save... we need good enough r2 and no invalids\n",
        "        if val_r2 > max(last_save_r2, min_save_r2):\n",
        "            if sum(get_count_invalid_preds(val_pred_coeff))==0:\n",
        "                # also check training invalids... Let's recompute with eval mode\n",
        "                model.eval()\n",
        "                eval_mode_train_preds=model(train_X.float()).cpu()\n",
        "                if sum(get_count_invalid_preds(eval_mode_train_preds))==0:\n",
        "                    if save_model_path:\n",
        "                        Path(save_model_path).unlink() # delete prev-best model\n",
        "                    model_save_name = f\"epoch={epoch},r2={val_r2:.4f},Invalids=0.pth\"\n",
        "                    save_model_path = f\"{model_dir}/{model_save_name}\"\n",
        "                    torch.save(model.state_dict(), save_model_path)\n",
        "                    last_save_epoch = epoch\n",
        "                    last_save_r2 = val_r2\n",
        "\n",
        "        if epoch % print_freq == 0:\n",
        "            invalid_train_MEFs, invalid_train_MDFs = get_count_invalid_preds(train_pred_coeff)\n",
        "            invalid_val_MEFs, invalid_val_MDFs = get_count_invalid_preds(val_pred_coeff)\n",
        "            train_r2 = get_r_squared(train_pred_coeff, train_bottleneck_X, train_y)\n",
        "            print(f\"[Epoch {epoch}]\")\n",
        "            print(f\"\\tTrain Set: Loss={train_loss.item():.3e}, R Squared={train_r2:.4f}, Invalid MEFs={invalid_train_MEFs}, Invalid MDFs={invalid_train_MDFs}\")\n",
        "            print(f\"\\tVal Set: Loss={val_loss.item():.3e}, R Squared={val_r2:.4f}, Invalid MEFs={invalid_val_MEFs}, Invalid MDFs={invalid_val_MDFs}\")\n",
        "\n",
        "        model.zero_grad()\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # stop if we aren't improving after 10k epochs\n",
        "        if best_epoch and epoch > 10000 + best_epoch:\n",
        "            print(\"Early stopping as we haven't made an improvement on validation set in 10,000 epochs.\")\n",
        "            break\n",
        "    \n",
        "    print_results(train_losses, train_pred_coeff, train_bottleneck_X, train_y,\n",
        "                  val_losses, val_pred_coeff, val_bottleneck_X, val_y, model_dir)\n",
        "    print(f\"best R Squared seen on epoch {best_epoch}: {best_r2:.4f}\")\n",
        "    if save_model_path:\n",
        "        print(f\"best R Squared with no invalids predicted in train/val seen on epoch {last_save_epoch}: {last_save_r2:.4f}\")\n",
        "        with open(f\"{save_model_path[:-4]}.results.txt\", 'w+') as f:\n",
        "            f.write(\"Val Set:\")\n",
        "            f.write(f\"\\tMean Absolute Error={best_model_mae:.2f}\")\n",
        "            f.write(f\"\\tR Squared={best_r2:.4f}\")\n",
        "    else:\n",
        "        print(f\"No model was saved because no model that had no train/val invalids reached {min_save_r2} validation R2.\")\n",
        "        \n",
        "    return save_model_path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### param tuning"
      ],
      "metadata": {
        "id": "vfcTBVn9FrR-"
      },
      "id": "vfcTBVn9FrR-"
    },
    {
      "cell_type": "code",
      "source": [
        "train_set, val_set = data_sets[\"train\"], data_sets[\"val\"]      \n",
        "train_X, train_bottleneck_X, train_y = train_set[\"X\"], train_set[\"bottleneck_X\"], train_set[\"y\"]\n",
        "val_X, val_bottleneck_X, val_y = val_set[\"X\"], val_set[\"bottleneck_X\"], val_set[\"y\"]\n",
        "input_size = train_X.shape[-1]\n",
        "output_size = 3  # 3 means we have an intercept\n",
        "\n",
        "### Tune Params Below ###\n",
        "hidden_size = 32\n",
        "final_point_only = True\n",
        "num_layers = 1\n",
        "dropout = 0\n",
        "batch_size = 1024\n",
        "learning_rate = .003\n",
        "weight_decay = .01\n",
        "loss_function = mse_loss_l1_coeff_reg\n",
        "MEF_reg_weight, MDF_reg_weight = 1e7, 1e7\n",
        "model_dir_prefix = \"predict_final_in_seq8_BN\"\n",
        "epochs = 400\n",
        "min_save_r2 = .86\n",
        "max_save_mae = 150000\n",
        "print_freq=20\n",
        "# evaluate\n",
        "save_model_path = train_model_with_params_batched(train_X, val_X, train_bottleneck_X, val_bottleneck_X, train_y, val_y,  # data\n",
        "                            input_size, hidden_size, output_size, final_point_only, num_layers, dropout,  # model settings\n",
        "                            learning_rate, weight_decay,  # optimizer settings\n",
        "                            loss_function, MEF_reg_weight, MDF_reg_weight,  # loss function settings\n",
        "                            model_dir_prefix, batch_size, epochs, print_freq, min_save_r2, max_save_mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "48f79cf624ea41229db24af7f7307eaa",
            "018f158461264820a43037233dc3843d",
            "5ce0b73fc6f843138c8b76f290562c69",
            "5d58cbdd7b944e99a9a24d2f7c9d3948",
            "1ccca095afed40f3a7d93abf2c94749b",
            "90ee2656eb3e4bd5a0d1189cac2d521c",
            "138722bc77c3400389ef616905904eaf",
            "7331c03842214571a355d32dc4f98865",
            "163dbaf1211a44d39d2faf30e2509295",
            "843889c691d04f938ad4bfdf5a4f3a6b",
            "05c854c5dda546acabb9da4ddad5b0ce"
          ]
        },
        "id": "NdIOFfthFwW0",
        "outputId": "b6647c26-ddca-4ece-b0c1-b6bb832d8706"
      },
      "id": "NdIOFfthFwW0",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Settings:\n",
            "\tinput_size=4\n",
            "\thidden_size=32\n",
            "\toutput_size=3\n",
            "\tfinal_point_only=True\n",
            "\tnum_layers=1\n",
            "\tdropout=0\n",
            "Optimizer Settings:\n",
            "\tlearning_rate=0.003\n",
            "\tweight_decay=0.01\n",
            "Loss Function Settings:\n",
            "\tloss_function=<function mse_loss_l1_coeff_reg at 0x7f4896783670>\n",
            "\tMEF_reg_weight=10000000.0\n",
            "\tMDF_reg_weight=10000000.0\n",
            "Train Process Settings:\n",
            "\tbatch_size=1024\n",
            "\tepochs=400\n",
            "\tmin_save_r2=0.86\n",
            "\tmax_save_mae=150000\n",
            "Features: Load, VRE, Hour, Day_of_Year\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/400 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48f79cf624ea41229db24af7f7307eaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0]\n",
            "\tTrain Set: Loss=3.377e+11, R Squared=0.0009, Invalid MEFs=0, Invalid MDFs=145\n",
            "\tVal Set: Loss=3.254e+11, R Squared=0.0009, Invalid MEFs=0, Invalid MDFs=55\n",
            "[Epoch 20]\n",
            "\tTrain Set: Loss=1.557e+11, R Squared=0.5192, Invalid MEFs=8, Invalid MDFs=17\n",
            "\tVal Set: Loss=1.534e+11, R Squared=0.5199, Invalid MEFs=3, Invalid MDFs=5\n",
            "[Epoch 40]\n",
            "\tTrain Set: Loss=1.098e+11, R Squared=0.7627, Invalid MEFs=53, Invalid MDFs=7\n",
            "\tVal Set: Loss=8.460e+10, R Squared=0.7663, Invalid MEFs=16, Invalid MDFs=3\n",
            "[Epoch 60]\n",
            "\tTrain Set: Loss=4.907e+10, R Squared=0.8432, Invalid MEFs=2, Invalid MDFs=0\n",
            "\tVal Set: Loss=4.880e+10, R Squared=0.8440, Invalid MEFs=0, Invalid MDFs=0\n",
            "[Epoch 80]\n",
            "\tTrain Set: Loss=4.118e+10, R Squared=0.8647, Invalid MEFs=0, Invalid MDFs=0\n",
            "\tVal Set: Loss=4.286e+10, R Squared=0.8630, Invalid MEFs=0, Invalid MDFs=0\n",
            "[Epoch 100]\n",
            "\tTrain Set: Loss=3.792e+10, R Squared=0.8754, Invalid MEFs=0, Invalid MDFs=0\n",
            "\tVal Set: Loss=4.057e+10, R Squared=0.8703, Invalid MEFs=0, Invalid MDFs=0\n",
            "[Epoch 120]\n",
            "\tTrain Set: Loss=3.711e+10, R Squared=0.8806, Invalid MEFs=1, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.884e+10, R Squared=0.8759, Invalid MEFs=0, Invalid MDFs=0\n",
            "[Epoch 140]\n",
            "\tTrain Set: Loss=3.523e+10, R Squared=0.8866, Invalid MEFs=1, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.917e+10, R Squared=0.8772, Invalid MEFs=1, Invalid MDFs=0\n",
            "[Epoch 160]\n",
            "\tTrain Set: Loss=3.393e+10, R Squared=0.8885, Invalid MEFs=0, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.795e+10, R Squared=0.8787, Invalid MEFs=0, Invalid MDFs=0\n",
            "[Epoch 180]\n",
            "\tTrain Set: Loss=3.544e+10, R Squared=0.8906, Invalid MEFs=3, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.818e+10, R Squared=0.8780, Invalid MEFs=0, Invalid MDFs=0\n",
            "[Epoch 200]\n",
            "\tTrain Set: Loss=3.956e+10, R Squared=0.8934, Invalid MEFs=10, Invalid MDFs=0\n",
            "\tVal Set: Loss=4.065e+10, R Squared=0.8795, Invalid MEFs=4, Invalid MDFs=0\n",
            "[Epoch 220]\n",
            "\tTrain Set: Loss=3.186e+10, R Squared=0.8953, Invalid MEFs=0, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.805e+10, R Squared=0.8784, Invalid MEFs=0, Invalid MDFs=0\n",
            "[Epoch 240]\n",
            "\tTrain Set: Loss=3.684e+10, R Squared=0.8954, Invalid MEFs=7, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.975e+10, R Squared=0.8773, Invalid MEFs=2, Invalid MDFs=0\n",
            "[Epoch 260]\n",
            "\tTrain Set: Loss=3.099e+10, R Squared=0.8982, Invalid MEFs=0, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.793e+10, R Squared=0.8788, Invalid MEFs=0, Invalid MDFs=0\n",
            "[Epoch 280]\n",
            "\tTrain Set: Loss=3.102e+10, R Squared=0.8981, Invalid MEFs=0, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.937e+10, R Squared=0.8767, Invalid MEFs=1, Invalid MDFs=0\n",
            "[Epoch 300]\n",
            "\tTrain Set: Loss=3.055e+10, R Squared=0.8996, Invalid MEFs=0, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.948e+10, R Squared=0.8768, Invalid MEFs=1, Invalid MDFs=1\n",
            "[Epoch 320]\n",
            "\tTrain Set: Loss=3.257e+10, R Squared=0.8999, Invalid MEFs=3, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.900e+10, R Squared=0.8775, Invalid MEFs=1, Invalid MDFs=0\n",
            "[Epoch 340]\n",
            "\tTrain Set: Loss=3.092e+10, R Squared=0.9006, Invalid MEFs=1, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.936e+10, R Squared=0.8765, Invalid MEFs=1, Invalid MDFs=0\n",
            "[Epoch 360]\n",
            "\tTrain Set: Loss=3.045e+10, R Squared=0.9023, Invalid MEFs=1, Invalid MDFs=0\n",
            "\tVal Set: Loss=3.913e+10, R Squared=0.8771, Invalid MEFs=1, Invalid MDFs=0\n",
            "[Epoch 380]\n",
            "\tTrain Set: Loss=3.772e+10, R Squared=0.9035, Invalid MEFs=11, Invalid MDFs=2\n",
            "\tVal Set: Loss=4.239e+10, R Squared=0.8772, Invalid MEFs=5, Invalid MDFs=1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best R Squared seen on epoch 221: 0.8804\n",
            "Best MAE seen on epoch 172: 140122.67\n",
            "Best-R2-model with R2 above min_save_r2=0.86 and 0 invalid coefficients predicted on train/test sets:\n",
            "\tValidation R2: 0.8803\n",
            "\tValidation MAE: 140122.67\n",
            "\tEpoch seen: 172\n",
            "\tModel file: epoch=172,r2=0.8803,mae=140122,Invalids=0.pth\n",
            "Best-MAE-model with MAE below max_save_mae=150000 and 0 invalid coefficients predicted on train/test sets:\n",
            "\tValidation R2: 0.8803\n",
            "\tValidation MAE: 140122.67\n",
            "\tEpoch seen: 172\n",
            "\tModel file: epoch=172,r2=0.8803,mae=140122,Invalids=0.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqgcArQqy5cg",
        "outputId": "331adb91-9c07-4dc2-c9c2-1a31eb78be79"
      },
      "id": "PqgcArQqy5cg",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14443, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_point_only = False\n",
        "train_set, val_set = data_sets[\"train\"], data_sets[\"val\"]      \n",
        "train_X, train_bottleneck_X, train_y = train_set[\"X\"], train_set[\"bottleneck_X\"], train_set[\"y\"]\n",
        "val_X, val_bottleneck_X, val_y = val_set[\"X\"], val_set[\"bottleneck_X\"], val_set[\"y\"]\n",
        "\n",
        "if final_point_only:\n",
        "    train_bottleneck_X = torch.unsqueeze(train_bottleneck_X[:,-1,:], 1)\n",
        "    val_bottleneck_X = torch.unsqueeze(val_bottleneck_X[:,-1,:], 1)\n",
        "    train_y = torch.unsqueeze(train_y[:,-1], 1)\n",
        "    val_y = torch.unsqueeze(val_y[:,-1], 1)\n",
        "\n",
        "model = LSTM(input_size, hidden_size, output_size, final_point_only, num_layers, dropout)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "# tell model we are training\n",
        "model.train()\n",
        "train_pred_coeff = model(train_X.float())"
      ],
      "metadata": {
        "id": "8I8vfs5iyXIx"
      },
      "id": "8I8vfs5iyXIx",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred_coeff.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGdznlt7zJ2r",
        "outputId": "207c8495-187d-4e55-c83d-bc05fadfc645"
      },
      "id": "bGdznlt7zJ2r",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14443, 8, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred_coeff[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srAyNJOxJjAI",
        "outputId": "3dcc6d12-8992-4223-edba-bbac4400fd39"
      },
      "id": "srAyNJOxJjAI",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0821,  0.0328,  0.0419],\n",
              "        [-0.1009,  0.0313,  0.0490],\n",
              "        [-0.1116,  0.0303,  0.0497],\n",
              "        [-0.1230,  0.0308,  0.0537],\n",
              "        [-0.1195,  0.0267,  0.0574],\n",
              "        [-0.1183,  0.0274,  0.0567],\n",
              "        [-0.1202,  0.0226,  0.0591],\n",
              "        [-0.1184,  0.0256,  0.0556]], device='cuda:0',\n",
              "       grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = get_y_pred(train_pred_coeff, train_bottleneck_X)"
      ],
      "metadata": {
        "id": "zP-F0bppzruY"
      },
      "id": "zP-F0bppzruY",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ3tQGYbz2AK",
        "outputId": "35bdb420-11e4-45a6-d95b-5f930b5e4a9f"
      },
      "id": "VJ3tQGYbz2AK",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14443, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLSWb4rz1hpy",
        "outputId": "4dbd979b-6402-4944-e3a5-7b006d69a4ea"
      },
      "id": "zLSWb4rz1hpy",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14443, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g861CPnTKQGA",
        "outputId": "40b8e9f9-7e8e-43e7-8b9b-c91484c86a3f"
      },
      "id": "g861CPnTKQGA",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([104.5600,  93.8499,  66.5238,  31.8933,  -4.7518, -59.5235, -92.0250,\n",
              "         30.1953], device='cuda:0', grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pobejekWKQD1",
        "outputId": "4419b41e-30d6-4946-9ae3-9b33c2fbe9d9"
      },
      "id": "pobejekWKQD1",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-337029.7812, -243021.8281, -144846.7969,  -24776.5703,   49254.1367,\n",
              "          88759.6875, 1101974.1250, -860734.4375], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.MSELoss()(y_pred, train_y)\n"
      ],
      "metadata": {
        "id": "AyNTATP3zrYx"
      },
      "id": "AyNTATP3zrYx",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hh3KyLA34rf",
        "outputId": "29025869-660b-4e2a-87b1-e8a0316f4f93"
      },
      "id": "0Hh3KyLA34rf",
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.0439e+11, device='cuda:0', grad_fn=<MseLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inference on all data"
      ],
      "metadata": {
        "id": "d7rNwHtGa1wX"
      },
      "id": "d7rNwHtGa1wX"
    },
    {
      "cell_type": "code",
      "source": [
        "## below we can load specific models instead of best one found in most recent experiment\n",
        "model_path= \"drive/MyDrive/NN_MEFs/lstm_models/predict_all_in_seq8/2022_12_08-12:36:39_AM/epoch=998,r2=0.8741,Invalids=0.pth\"\n",
        "\n",
        "train_set, val_set = data_sets[\"train\"], data_sets[\"val\"]      \n",
        "train_X, train_bottleneck_X, train_y = train_set[\"X\"], train_set[\"bottleneck_X\"], train_set[\"y\"]\n",
        "val_X, val_bottleneck_X, val_y = val_set[\"X\"], val_set[\"bottleneck_X\"], val_set[\"y\"]\n",
        "input_size = train_X.shape[-1]\n",
        "output_size = 3  # 3 means we have an intercept\n",
        "hidden_size = 32\n",
        "final_point_only = False\n",
        "num_layers = 1\n",
        "dropout = 0\n",
        "\n",
        "model = LSTM(input_size, hidden_size, output_size, final_point_only, num_layers, dropout)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model.eval()\n",
        "\n",
        "train_pred_coeff = model(train_X.float())\n",
        "val_pred_coeff = model(val_X.float())\n"
      ],
      "metadata": {
        "id": "_aGp7ISVb0y8"
      },
      "id": "_aGp7ISVb0y8",
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_pred = get_y_pred(train_pred_coeff, train_bottleneck_X)"
      ],
      "metadata": {
        "id": "Xzu9Fu4wZ6ZD"
      },
      "id": "Xzu9Fu4wZ6ZD",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y_pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x-M_96gZ6P5",
        "outputId": "919cad51-3c97-4c95-a955-ca1d7a019a53"
      },
      "id": "4x-M_96gZ6P5",
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([14443, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score(train_y.cpu().detach().numpy(), train_y_pred.cpu().detach().numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4G-XBQTZ6LF",
        "outputId": "73de7ee6-d58d-4348-8129-7d223a3059c0"
      },
      "id": "W4G-XBQTZ6LF",
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8834384493448952"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[r2_score(y, y_pred) for y, y_pred in \\\n",
        " zip(train_y.permute(1,0).cpu().detach().numpy(), train_y_pred.permute(1,0).cpu().detach().numpy())]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J93Aym-wZ6Ex",
        "outputId": "4cd71904-4aea-4b94-f467-e4eb4dab89c0"
      },
      "id": "J93Aym-wZ6Ex",
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8529343380942997,\n",
              " 0.8696363903200108,\n",
              " 0.8795923203147114,\n",
              " 0.8862990346813329,\n",
              " 0.8909820117950451,\n",
              " 0.8939545501303765,\n",
              " 0.8963344742449033,\n",
              " 0.897774475458195]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_y_pred = get_y_pred(val_pred_coeff, val_bottleneck_X)\n",
        "print(f\"overall val r2: {r2_score(val_y.cpu().detach().numpy(), val_y_pred.cpu().detach().numpy())}\")\n",
        "print(\"val r2 by sequence position:\")\n",
        "print([r2_score(y, y_pred) for y, y_pred in \\\n",
        " zip(val_y.permute(1,0).cpu().detach().numpy(), val_y_pred.permute(1,0).cpu().detach().numpy())])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYBqgfGmc1QH",
        "outputId": "4fc5e450-4bca-465f-8eee-7fcf5684453c"
      },
      "id": "EYBqgfGmc1QH",
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "overall val r2: 0.8741031307517685\n",
            "val r2 by sequence position:\n",
            "[0.8568319386070357, 0.8682907729195138, 0.8745469021399369, 0.8777426423604695, 0.8794796853834416, 0.8781586552040923, 0.8787055918233209, 0.8790688571549825]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S0Xum_K0c1Mi"
      },
      "id": "S0Xum_K0c1Mi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QqKvf2Q0c0-Y"
      },
      "id": "QqKvf2Q0c0-Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_dims = [512,256]\n",
        "bias_term = True\n",
        "dropout_p = 0.5\n",
        "n_input = train_x.shape[1]\n",
        "\n",
        "\n",
        "model = get_model(n_input, hidden_dims, n_out, dropout_p)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load(best_model_path))\n",
        "model.eval()\n",
        "\n",
        "train_pred_coeff = model(train_x.float()).cpu()\n",
        "val_pred_coeff = model(val_x.float()).cpu()\n",
        "test_pred_coeff = model(test_x.float()).cpu()\n",
        "\n",
        "print(\"R Squared:\")\n",
        "print(f\"\\tTrain: {get_r_squared(train_pred_coeff, CAISO_train, bias_term):.4f}\")\n",
        "print(f\"\\tVal: {get_r_squared(val_pred_coeff, CAISO_val, bias_term):.4f}\")\n",
        "print(f\"\\tTest: {get_r_squared(test_pred_coeff, CAISO_test, bias_term):.4f}\")\n",
        "print(\"Mean Absolute Error:\")\n",
        "print(f\"\\tTrain: {get_mean_abs_err(train_pred_coeff, CAISO_train, bias_term):.2f}\")\n",
        "print(f\"\\tVal: {get_mean_abs_err(val_pred_coeff, CAISO_val, bias_term):.2f}\")\n",
        "print(f\"\\tTest: {get_mean_abs_err(test_pred_coeff, CAISO_test, bias_term):.2f}\")\n",
        "print(\"Count Invalid Values Predicted:\")\n",
        "invalid_train_MEFs, invalid_train_MDFs = get_count_invalid_preds(train_pred_coeff)\n",
        "invalid_val_MEFs, invalid_val_MDFs = get_count_invalid_preds(val_pred_coeff)\n",
        "invalid_test_MEFs, invalid_test_MDFs = get_count_invalid_preds(test_pred_coeff)\n",
        "print(f\"\\tTrain: Invalid MEFs={invalid_train_MEFs}, Invalid MDFs={invalid_train_MDFs}\")\n",
        "print(f\"\\tVal: Invalid MEFs={invalid_val_MEFs}, Invalid MDFs={invalid_val_MDFs}\")\n",
        "print(f\"\\tTest: Invalid MEFs={invalid_test_MEFs}, Invalid MDFs={invalid_test_MDFs}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DHacOOCZYoj",
        "outputId": "b7064058-d857-4b67-ba28-02d67b71d9ad"
      },
      "id": "6DHacOOCZYoj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R Squared:\n",
            "\tTrain: 0.8921\n",
            "\tVal: 0.8805\n",
            "\tTest: 0.8755\n",
            "Mean Absolute Error:\n",
            "\tTrain: 131028.76\n",
            "\tVal: 140016.71\n",
            "\tTest: 139890.26\n",
            "Count Invalid Values Predicted:\n",
            "\tTrain: Invalid MEFs=0, Invalid MDFs=0\n",
            "\tVal: Invalid MEFs=0, Invalid MDFs=0\n",
            "\tTest: Invalid MEFs=0, Invalid MDFs=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Put the MEFs and MDFs from all sets back together and in order into the original DF for viewing"
      ],
      "metadata": {
        "id": "fi3OLzVQPK_O"
      },
      "id": "fi3OLzVQPK_O"
    },
    {
      "cell_type": "code",
      "source": [
        "all_preds_w_timestamps = list(zip(CAISO_val.index, val_pred_coeff.detach().numpy())) \\\n",
        "                        + list(zip(CAISO_train.index, train_pred_coeff.detach().numpy())) \\\n",
        "                        + list(zip(CAISO_test.index, test_pred_coeff.detach().numpy()))\n",
        "all_preds_w_timestamps.sort(key=lambda pair: pair[0])\n",
        "all_preds_ordered = np.array([pair[1] for pair in all_preds_w_timestamps])"
      ],
      "metadata": {
        "id": "uB50w20k_Iao"
      },
      "id": "uB50w20k_Iao",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_MEFs_ordered = all_preds_ordered[:,0]\n",
        "all_MDFs_ordered = all_preds_ordered[:,1]\n",
        "all_intercepts_ordered = all_preds_ordered[:,2]"
      ],
      "metadata": {
        "id": "vHn1WJaZCXm2"
      },
      "id": "vHn1WJaZCXm2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CAISO_Data.loc[:,\"MEF\"] = all_MEFs_ordered\n",
        "CAISO_Data.loc[:,\"MDF\"] = all_MDFs_ordered\n",
        "if bias_term:\n",
        "    CAISO_Data.loc[:,\"Intercept\"] = all_intercepts_ordered\n",
        "\n",
        "#calculate some error stuff. rn i am thinking R2 is the best measure of error\n",
        "d_emissions = CAISO_Data.loc[:,'MEF'] * CAISO_Data.loc[:,'delta_Load'] \\\n",
        "            + CAISO_Data.loc[:,'MDF'] * CAISO_Data.loc[:,'delta_VRE']\n",
        "if bias_term:\n",
        "    d_emissions += CAISO_Data.loc[:,\"Intercept\"]\n",
        "CAISO_Data.loc[:,'Predicted_delta_Total_CO2_Emissions'] = d_emissions\n",
        "CAISO_Data.loc[:,'Error']=CAISO_Data.loc[:,'Predicted_delta_Total_CO2_Emissions']-CAISO_Data.loc[:,'delta_Total_CO2_Emissions']\n",
        "CAISO_Data.loc[:,'%_Error']=np.abs(CAISO_Data.loc[:,'Error'])/np.abs(CAISO_Data.loc[:,'delta_Total_CO2_Emissions'])\n",
        "print(\"Whole Data Set:\")\n",
        "print(f\"\\tMean Emissions Change = {np.mean(np.abs(CAISO_Data['delta_Total_CO2_Emissions'])):.2f}\")\n",
        "print(f\"\\tR Squared = {r2_score(CAISO_Data['delta_Total_CO2_Emissions'], CAISO_Data['Predicted_delta_Total_CO2_Emissions']):.4f}\")\n",
        "print(f\"\\tMean Absolute Error = {mean_absolute_error(CAISO_Data['delta_Total_CO2_Emissions'], CAISO_Data['Predicted_delta_Total_CO2_Emissions']):.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDaE9gk8cX_g",
        "outputId": "e18f47bf-7d0a-4621-9d5d-615c99f75149"
      },
      "id": "aDaE9gk8cX_g",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whole Data Set:\n",
            "\tMean Emissions Change = 413165.73\n",
            "\tR Squared = 0.8864\n",
            "\tMean Absolute Error = 134598.78\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CAISO_Data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "HLrBWNZifiaF",
        "outputId": "5d4a38f3-9e47-4f9e-89cf-4d1c8a35cd42"
      },
      "id": "HLrBWNZifiaF",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Load      Net Load  Total_CO2_Emissions  \\\n",
              "2019-01-01 00:00:00  22822.964472  20502.358502         5.103942e+06   \n",
              "2019-01-01 01:00:00  21879.620618  19606.836908         4.867578e+06   \n",
              "2019-01-01 02:00:00  21257.454020  19056.267637         4.723101e+06   \n",
              "2019-01-01 03:00:00  20974.800758  18871.418601         4.693112e+06   \n",
              "2019-01-01 04:00:00  20327.083333  18012.666667         5.032423e+06   \n",
              "\n",
              "                     Total_SO2_Emissions  Total_NOX_Emissions          VRE  \\\n",
              "2019-01-01 00:00:00           425.327933          1632.821698  2320.593616   \n",
              "2019-01-01 01:00:00           404.315852          1557.650531  2272.780097   \n",
              "2019-01-01 02:00:00           383.695714          1496.197481  2201.182455   \n",
              "2019-01-01 03:00:00           380.561848          1466.329836  2103.388502   \n",
              "2019-01-01 04:00:00           711.911968          2391.657870  2314.666667   \n",
              "\n",
              "                      delta_Load  delta_Net_Load  delta_Total_CO2_Emissions  \\\n",
              "2019-01-01 00:00:00 -1285.054865    -1255.110267             -337029.794143   \n",
              "2019-01-01 01:00:00  -944.689268     -896.922625             -243021.833700   \n",
              "2019-01-01 02:00:00  -614.641020     -545.206677             -144846.797503   \n",
              "2019-01-01 03:00:00  -281.391674     -191.565227              -24776.569759   \n",
              "2019-01-01 04:00:00    30.416667       74.416667               49254.136541   \n",
              "\n",
              "                     delta_Total_SO2_Emissions  ...  Day_of_Week=3  \\\n",
              "2019-01-01 00:00:00                 -24.142180  ...          False   \n",
              "2019-01-01 01:00:00                 -21.594332  ...          False   \n",
              "2019-01-01 02:00:00                 -20.952957  ...          False   \n",
              "2019-01-01 03:00:00                  -2.164379  ...          False   \n",
              "2019-01-01 04:00:00                  69.703951  ...          False   \n",
              "\n",
              "                     Day_of_Week=4  Day_of_Week=5  Day_of_Week=6         MEF  \\\n",
              "2019-01-01 00:00:00          False          False          False  370.729431   \n",
              "2019-01-01 01:00:00          False          False          False  345.051025   \n",
              "2019-01-01 02:00:00          False          False          False  323.416351   \n",
              "2019-01-01 03:00:00          False          False          False  305.443024   \n",
              "2019-01-01 04:00:00          False          False          False  303.949066   \n",
              "\n",
              "                            MDF    Intercept  \\\n",
              "2019-01-01 00:00:00 -350.030640  6396.021973   \n",
              "2019-01-01 01:00:00 -323.291504  6071.847168   \n",
              "2019-01-01 02:00:00 -301.258514  5678.250977   \n",
              "2019-01-01 03:00:00 -282.996887  5341.076660   \n",
              "2019-01-01 04:00:00 -272.057770  5023.662109   \n",
              "\n",
              "                     Predicted_delta_Total_CO2_Emissions          Error  \\\n",
              "2019-01-01 00:00:00                       -459526.000872 -122496.206729   \n",
              "2019-01-01 01:00:00                       -304454.710093  -61432.876394   \n",
              "2019-01-01 02:00:00                       -172189.482236  -27342.684733   \n",
              "2019-01-01 03:00:00                        -55190.639304  -30414.069545   \n",
              "2019-01-01 04:00:00                         26216.649928  -23037.486613   \n",
              "\n",
              "                      %_Error  \n",
              "2019-01-01 00:00:00  0.363458  \n",
              "2019-01-01 01:00:00  0.252787  \n",
              "2019-01-01 02:00:00  0.188770  \n",
              "2019-01-01 03:00:00  1.227534  \n",
              "2019-01-01 04:00:00  0.467727  \n",
              "\n",
              "[5 rows x 37 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a367649-fc32-4a72-9bd2-225f8c53ff14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Load</th>\n",
              "      <th>Net Load</th>\n",
              "      <th>Total_CO2_Emissions</th>\n",
              "      <th>Total_SO2_Emissions</th>\n",
              "      <th>Total_NOX_Emissions</th>\n",
              "      <th>VRE</th>\n",
              "      <th>delta_Load</th>\n",
              "      <th>delta_Net_Load</th>\n",
              "      <th>delta_Total_CO2_Emissions</th>\n",
              "      <th>delta_Total_SO2_Emissions</th>\n",
              "      <th>...</th>\n",
              "      <th>Day_of_Week=3</th>\n",
              "      <th>Day_of_Week=4</th>\n",
              "      <th>Day_of_Week=5</th>\n",
              "      <th>Day_of_Week=6</th>\n",
              "      <th>MEF</th>\n",
              "      <th>MDF</th>\n",
              "      <th>Intercept</th>\n",
              "      <th>Predicted_delta_Total_CO2_Emissions</th>\n",
              "      <th>Error</th>\n",
              "      <th>%_Error</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2019-01-01 00:00:00</th>\n",
              "      <td>22822.964472</td>\n",
              "      <td>20502.358502</td>\n",
              "      <td>5.103942e+06</td>\n",
              "      <td>425.327933</td>\n",
              "      <td>1632.821698</td>\n",
              "      <td>2320.593616</td>\n",
              "      <td>-1285.054865</td>\n",
              "      <td>-1255.110267</td>\n",
              "      <td>-337029.794143</td>\n",
              "      <td>-24.142180</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>370.729431</td>\n",
              "      <td>-350.030640</td>\n",
              "      <td>6396.021973</td>\n",
              "      <td>-459526.000872</td>\n",
              "      <td>-122496.206729</td>\n",
              "      <td>0.363458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 01:00:00</th>\n",
              "      <td>21879.620618</td>\n",
              "      <td>19606.836908</td>\n",
              "      <td>4.867578e+06</td>\n",
              "      <td>404.315852</td>\n",
              "      <td>1557.650531</td>\n",
              "      <td>2272.780097</td>\n",
              "      <td>-944.689268</td>\n",
              "      <td>-896.922625</td>\n",
              "      <td>-243021.833700</td>\n",
              "      <td>-21.594332</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>345.051025</td>\n",
              "      <td>-323.291504</td>\n",
              "      <td>6071.847168</td>\n",
              "      <td>-304454.710093</td>\n",
              "      <td>-61432.876394</td>\n",
              "      <td>0.252787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 02:00:00</th>\n",
              "      <td>21257.454020</td>\n",
              "      <td>19056.267637</td>\n",
              "      <td>4.723101e+06</td>\n",
              "      <td>383.695714</td>\n",
              "      <td>1496.197481</td>\n",
              "      <td>2201.182455</td>\n",
              "      <td>-614.641020</td>\n",
              "      <td>-545.206677</td>\n",
              "      <td>-144846.797503</td>\n",
              "      <td>-20.952957</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>323.416351</td>\n",
              "      <td>-301.258514</td>\n",
              "      <td>5678.250977</td>\n",
              "      <td>-172189.482236</td>\n",
              "      <td>-27342.684733</td>\n",
              "      <td>0.188770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 03:00:00</th>\n",
              "      <td>20974.800758</td>\n",
              "      <td>18871.418601</td>\n",
              "      <td>4.693112e+06</td>\n",
              "      <td>380.561848</td>\n",
              "      <td>1466.329836</td>\n",
              "      <td>2103.388502</td>\n",
              "      <td>-281.391674</td>\n",
              "      <td>-191.565227</td>\n",
              "      <td>-24776.569759</td>\n",
              "      <td>-2.164379</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>305.443024</td>\n",
              "      <td>-282.996887</td>\n",
              "      <td>5341.076660</td>\n",
              "      <td>-55190.639304</td>\n",
              "      <td>-30414.069545</td>\n",
              "      <td>1.227534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2019-01-01 04:00:00</th>\n",
              "      <td>20327.083333</td>\n",
              "      <td>18012.666667</td>\n",
              "      <td>5.032423e+06</td>\n",
              "      <td>711.911968</td>\n",
              "      <td>2391.657870</td>\n",
              "      <td>2314.666667</td>\n",
              "      <td>30.416667</td>\n",
              "      <td>74.416667</td>\n",
              "      <td>49254.136541</td>\n",
              "      <td>69.703951</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>303.949066</td>\n",
              "      <td>-272.057770</td>\n",
              "      <td>5023.662109</td>\n",
              "      <td>26216.649928</td>\n",
              "      <td>-23037.486613</td>\n",
              "      <td>0.467727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows  37 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a367649-fc32-4a72-9bd2-225f8c53ff14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a367649-fc32-4a72-9bd2-225f8c53ff14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a367649-fc32-4a72-9bd2-225f8c53ff14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CAISO_Data.to_csv(f\"{best_model_dir}/CAISO_Data_2019_2021_NN_Ts.with_coeff_preds.csv\")"
      ],
      "metadata": {
        "id": "XG2_fHd5fmAI"
      },
      "id": "XG2_fHd5fmAI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len([val for val in CAISO_Data.loc[:,\"MEF\"] if val <=0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJWPn96SFkTa",
        "outputId": "1ee10191-30a4-4a58-f089-677458a2c182"
      },
      "id": "uJWPn96SFkTa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len([val for val in CAISO_Data.loc[:,\"MEF\"] if val >600])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89hutia2GEKj",
        "outputId": "12d38d99-8e8d-41a8-b34a-00e3fc3201b1"
      },
      "id": "89hutia2GEKj",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CAISO_Data.loc[:,\"MEF\"].max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2PyvXRSGoiX",
        "outputId": "2bdc08c2-f712-4523-f1b7-d0dc015a8764"
      },
      "id": "F2PyvXRSGoiX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "719.43835"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48f79cf624ea41229db24af7f7307eaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_018f158461264820a43037233dc3843d",
              "IPY_MODEL_5ce0b73fc6f843138c8b76f290562c69",
              "IPY_MODEL_5d58cbdd7b944e99a9a24d2f7c9d3948"
            ],
            "layout": "IPY_MODEL_1ccca095afed40f3a7d93abf2c94749b"
          }
        },
        "018f158461264820a43037233dc3843d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90ee2656eb3e4bd5a0d1189cac2d521c",
            "placeholder": "",
            "style": "IPY_MODEL_138722bc77c3400389ef616905904eaf",
            "value": "100%"
          }
        },
        "5ce0b73fc6f843138c8b76f290562c69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7331c03842214571a355d32dc4f98865",
            "max": 400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_163dbaf1211a44d39d2faf30e2509295",
            "value": 400
          }
        },
        "5d58cbdd7b944e99a9a24d2f7c9d3948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843889c691d04f938ad4bfdf5a4f3a6b",
            "placeholder": "",
            "style": "IPY_MODEL_05c854c5dda546acabb9da4ddad5b0ce",
            "value": " 400/400 [04:11&lt;00:00,  1.69it/s]"
          }
        },
        "1ccca095afed40f3a7d93abf2c94749b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ee2656eb3e4bd5a0d1189cac2d521c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138722bc77c3400389ef616905904eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7331c03842214571a355d32dc4f98865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "163dbaf1211a44d39d2faf30e2509295": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "843889c691d04f938ad4bfdf5a4f3a6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05c854c5dda546acabb9da4ddad5b0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}