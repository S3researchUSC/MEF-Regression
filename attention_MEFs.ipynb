{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3b9786",
   "metadata": {
    "id": "ee3b9786"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pathlib import Path\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f30fe9",
   "metadata": {
    "id": "a5f30fe9"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08e1ec4a",
   "metadata": {
    "id": "08e1ec4a"
   },
   "outputs": [],
   "source": [
    "data_file = os.path.join(os.getcwd(), \"CAISO_Data_2019_2021_NN.csv\")\n",
    "model_save_dir = os.path.join(os.getcwd(), \"lstm_models\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a15b1a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3cc09e",
   "metadata": {
    "id": "ab3cc09e"
   },
   "source": [
    "## Data Loading and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cClcvOnQaW5q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cClcvOnQaW5q",
    "outputId": "a85f5ad1-a146-4cd3-87ef-94591b7bf065"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num examples for seq_len=24, block_len=2*24: 13700\n",
      "num examples for seq_len=24, block_len=3*24: 17886\n",
      "num examples for seq_len=12, block_len=2*24: 20276\n",
      "num examples for seq_len=12, block_len=3*24: 22278\n",
      "num examples for seq_len=3, block_len=2*24: 25208\n",
      "num examples for seq_len=3, block_len=3*24: 25572\n",
      "num examples for seq_len=8, block_len=1*24: 18632\n"
     ]
    }
   ],
   "source": [
    "def get_num_examples_in_block(block_len, seq_len):\n",
    "    return max(block_len - seq_len + 1, 0)\n",
    "\n",
    "def get_num_examples_in_data(block_len, seq_len, total_size):\n",
    "    num_full_blocks = total_size // block_len\n",
    "    block_remainder = total_size % block_len\n",
    "    num_examples = num_full_blocks * get_num_examples_in_block(block_len, seq_len) \\\n",
    "                 + get_num_examples_in_block(block_remainder, seq_len)\n",
    "    return num_examples\n",
    "\n",
    "seq_len = 24\n",
    "block_len = 3 * 24  # chunk data in blocks of 3 days for splitting to train/val/test\n",
    "total_size = 24 * 365 * 3 + 24\n",
    "print(f\"num examples for seq_len=24, block_len=2*24: {get_num_examples_in_data(2*24, 24, total_size)}\")\n",
    "print(f\"num examples for seq_len=24, block_len=3*24: {get_num_examples_in_data(3*24, 24, total_size)}\")\n",
    "print(f\"num examples for seq_len=12, block_len=2*24: {get_num_examples_in_data(2*24, 12, total_size)}\")\n",
    "print(f\"num examples for seq_len=12, block_len=3*24: {get_num_examples_in_data(3*24, 12, total_size)}\")\n",
    "print(f\"num examples for seq_len=3, block_len=2*24: {get_num_examples_in_data(2*24, 3, total_size)}\")\n",
    "print(f\"num examples for seq_len=3, block_len=3*24: {get_num_examples_in_data(3*24, 3, total_size)}\")\n",
    "print(f\"num examples for seq_len=8, block_len=1*24: {get_num_examples_in_data(1*24, 8, total_size)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XRzIKschTd9R",
   "metadata": {
    "id": "XRzIKschTd9R"
   },
   "source": [
    "Specify:  \n",
    "* number of days in each block for train/val/test (e.g. 6:2:2 or 9:3:3)\n",
    "* sequence length (e.g. 3, 8, 12, ...).\n",
    "\n",
    "We will load in data and preprocess it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "44e7e48e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44e7e48e",
    "outputId": "7867f7b1-7ccb-4fae-d73a-15d3bead6eeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The last block of points assigned is in the val set and has 0.5416666666666666 day(s) of points.\n",
      "number of points in train set: 15582\n",
      "number of points in val set: 5368\n",
      "number of points in test set: 5355\n",
      "\n",
      "After splitting blocks to example sequences:\n",
      "Number of example sequences in train set: 15158 (60.5%)\n",
      "Number of example sequences in val set: 4944 (19.7%)\n",
      "Number of example sequences in test set: 4935 (19.7%)\n"
     ]
    }
   ],
   "source": [
    "# read in the processed data. there should be zero nans or missing data.\n",
    "CAISO_Data = pd.read_csv(data_file, index_col=0)\n",
    "CAISO_Data.index = pd.to_datetime(CAISO_Data.index)\n",
    "\n",
    "# Adding some temporal features\n",
    "CAISO_Data.loc[:,\"Day_of_Year\"] = [instant.timetuple().tm_yday for instant in CAISO_Data.index]\n",
    "CAISO_Data.loc[:,\"Hour\"] = CAISO_Data.index.hour\n",
    "\n",
    "num_samples = len(CAISO_Data)\n",
    "\n",
    "# create train, validation and test data\n",
    "data_sets = {\"train\": {\"days_in_block\": 6}, \"val\": {\"days_in_block\": 2}, \"test\": {\"days_in_block\": 2}}\n",
    "seq_len = 4\n",
    "for data in data_sets.values():\n",
    "    data[\"block_len\"] = data[\"days_in_block\"] * 24 + seq_len - 1\n",
    "set_assignments = []\n",
    "remaining_samples_to_assign = num_samples\n",
    "cur_set_idx = 0\n",
    "set_names = list(data_sets.keys())\n",
    "while remaining_samples_to_assign:\n",
    "    cur_set = set_names[cur_set_idx]\n",
    "    samples_to_assign = min(remaining_samples_to_assign, data_sets[cur_set][\"block_len\"])\n",
    "    set_assignments.extend([cur_set for i in range(samples_to_assign)])\n",
    "\n",
    "    cur_set_idx = (cur_set_idx + 1) % len(set_names)\n",
    "    remaining_samples_to_assign -= samples_to_assign\n",
    "\n",
    "set_assignments = np.array(set_assignments)\n",
    "for set_name, data in data_sets.items():\n",
    "    data[\"mask\"] = set_assignments == set_name\n",
    "\n",
    "points_in_last_assignment = 0\n",
    "while set_assignments[-(points_in_last_assignment + 1)] == set_assignments[-1]:\n",
    "    points_in_last_assignment += 1\n",
    "last_assignment_set = set_assignments[-1]\n",
    "print(f\"The last block of points assigned is in the {last_assignment_set} set and has {points_in_last_assignment/24} day(s) of points.\")\n",
    "\n",
    "for set_name, data in data_sets.items():\n",
    "    print(f\"number of points in {set_name} set: {sum(data['mask'])}\")\n",
    "\n",
    "\n",
    "## Specify features to use\n",
    "# feature_cols = ['Load', 'VRE', 'Hour', 'Month', 'Day', 'Pas_Temp', 'SJ_Temp', 'NH_Temp', 'SB_Temp', 'Sac_Temp', 'Fres_Temp', 'LB_Temp']\n",
    "# feature_cols = ['Load', 'VRE', 'Hour', 'Day_of_Year', 'Is_Weekend', 'Pas_Temp', 'SJ_Temp', 'NH_Temp', 'SB_Temp', 'Sac_Temp', 'Fres_Temp', 'LB_Temp']\n",
    "# feature_cols = ['Load', 'VRE', 'Hour', 'Day_of_Year', 'Pas_Temp', 'SJ_Temp', 'NH_Temp', 'SB_Temp', 'Sac_Temp', 'Fres_Temp', 'LB_Temp']\n",
    "# feature_cols.extend([f\"Day_of_Week={day_of_week}\" for day_of_week in range(7)])\n",
    "\n",
    "feature_cols = ['Load', 'VRE', 'Hour', 'Day_of_Year']\n",
    "# feature_cols.extend([f\"Load_t-{i}\" for i in prev_time_steps] + [f\"VRE_t-{i}\" for i in prev_time_steps])\n",
    "# feature_cols.extend([\"Load_d1\", \"Load_d2\", \"VRE_d1\", \"VRE_d2\"])\n",
    "# feature_cols.extend([\"delta_Load\", \"delta_VRE\"])\n",
    "\n",
    "\n",
    "# specify x, bottleneck features, and y data\n",
    "bottleneck_feature_cols = [\"delta_Load\", \"delta_VRE\"]\n",
    "y_col = 'delta_Total_CO2_Emissions'\n",
    "\n",
    "for set_name, data in data_sets.items():\n",
    "    CAISO_subset = CAISO_Data.loc[data[\"mask\"]]\n",
    "    data[\"X\"] = CAISO_subset[feature_cols].values.astype(np.float32)\n",
    "    data[\"y\"] = CAISO_subset[y_col].values.astype(np.float32)\n",
    "    data[\"bottleneck_X\"] = CAISO_subset[bottleneck_feature_cols].values.astype(np.float32)\n",
    "\n",
    "# standardize data based on mean and variance of train data\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(data_sets[\"train\"][\"X\"])\n",
    "for data in data_sets.values():\n",
    "    data[\"X\"] = scaler.transform(data[\"X\"])\n",
    "\n",
    "# seperate data to contiguous blocks\n",
    "def reshape_to_blocks(arr, block_size):\n",
    "    block_arr = []\n",
    "    start_pos = 0\n",
    "    while start_pos < len(arr):\n",
    "        end = min(start_pos + block_size, len(arr))\n",
    "        block_arr.append(arr[start_pos: end])\n",
    "        start_pos = end\n",
    "    return block_arr\n",
    "\n",
    "def split_blocks_to_seqs(blocks, seq_len=seq_len):\n",
    "    \"\"\"\n",
    "    blocks: num_blocks x block_len [x features]\n",
    "\n",
    "    ret:\n",
    "      seqs: num_seqs x seq_len [x features]\n",
    "    \"\"\"\n",
    "    seqs = []\n",
    "    for block in blocks:\n",
    "        block_len = len(block)\n",
    "        assert block_len >= seq_len\n",
    "        seqs.extend([block[start: start+seq_len] for start in range(block_len - seq_len)])\n",
    "    return np.array(seqs)\n",
    "\n",
    "# split data to contiguous blocks, and expand to example sequences via sliding window over blocks\n",
    "for data in data_sets.values():\n",
    "    for key in [\"X\", \"y\", \"bottleneck_X\"]:\n",
    "        data[key] = reshape_to_blocks(data[key], data[\"block_len\"])\n",
    "        data[key] = split_blocks_to_seqs(data[key], seq_len)\n",
    "        data[key] = torch.tensor(data[key]).to(device)\n",
    "\n",
    "print(f\"\\nAfter splitting blocks to example sequences:\")\n",
    "total_examples = sum(len(data[\"X\"]) for data in data_sets.values())\n",
    "for set_name, data in data_sets.items():\n",
    "    print(f\"Number of example sequences in {set_name} set: {len(data['X'])} ({100*len(data['X'])/total_examples:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "jMqj3kx1S4Pt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMqj3kx1S4Pt",
    "outputId": "ff5ec9a7-f7bf-47f8-91bb-994d214a2f39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15158, 4])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets[\"train\"][\"y\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4JXpruwnsO7F",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JXpruwnsO7F",
    "outputId": "3394d1d3-34fd-4623-e021-eddc48ec14f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15158, 4, 4])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets[\"train\"][\"X\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74d18ea",
   "metadata": {
    "id": "d74d18ea"
   },
   "source": [
    "## define model and set params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7a1f3331",
   "metadata": {
    "id": "7a1f3331"
   },
   "outputs": [],
   "source": [
    "def get_model(n_input, hidden_dim, n_out, dropout_p):\n",
    "    \n",
    "    layers = [nn.lstm(input_size=n_input, hidden_size=hidden_dim,\n",
    "                      batch_first=True, proj_size=n_out, num_layers=1),\n",
    "             ]\n",
    "    \n",
    "    model = nn.Sequential(*layers)\n",
    "    return model\n",
    "\n",
    "class LSTM_old(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                 final_point_only, num_layers=1, dropout=0, debug=False):\n",
    "        super().__init__()\n",
    "        self.final_point_only = final_point_only\n",
    "        self.debug = debug\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                            batch_first=True, num_layers=num_layers, dropout=dropout)\n",
    "        self.batchnorm1d = nn.BatchNorm1d(hidden_size)\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, (hn, cn) = self.lstm(input_seq)\n",
    "        if self.final_point_only:\n",
    "            lstm_out = torch.unsqueeze(lstm_out[:,-1,:], 1) # batch x seq_len x hidden\n",
    "        lstm_out = self.batchnorm1d(lstm_out.permute(0,2,1)) # batch x hidden x seq_len is needed as input\n",
    "        lstm_out = lstm_out.permute(0, 2, 1) # switch hidden and seq_len dims back\n",
    "        # lstm_out = self.dropout(lstm_out)\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        if self.debug:\n",
    "            print(f\"lstm_out: {lstm_out}\")\n",
    "            print(f\"hn: {hn}\")\n",
    "            print(f\"cn: {cn}\")\n",
    "            print(f\"self.fc: {self.fc}\")\n",
    "            print(f\"fc_out: {fc_out}\")\n",
    "        return fc_out\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                 final_point_only, num_layers=1, dropout=0, debug=False):\n",
    "        super().__init__()\n",
    "        self.final_point_only = final_point_only\n",
    "        self.debug = debug\n",
    "        self.num_layers = num_layers\n",
    "        lstm_layers = [nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)]\n",
    "        lstm_layers += [nn.LSTM(input_size=hidden_size, hidden_size=hidden_size,\n",
    "                            batch_first=True) for l in range(num_layers - 1)] # subsequent layers take hidden dims as input\n",
    "        self.lstm_layers = nn.ModuleList(lstm_layers)\n",
    "        self.drop_layers = nn.ModuleList([nn.Dropout(dropout) for l in range(num_layers)])\n",
    "        self.bn_layers = nn.ModuleList([nn.BatchNorm1d(hidden_size) for l in range(num_layers)])\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        for l in range(self.num_layers):\n",
    "            lstm_out, (hn, cn) = self.lstm_layers[l](input_seq)\n",
    "            lstm_out = self.bn_layers[l](lstm_out.permute(0,2,1)) # batch x hidden x seq_len is needed as input\n",
    "            lstm_out = lstm_out.permute(0, 2, 1) # switch hidden and seq_len dims back\n",
    "            lstm_out = self.drop_layers[l](lstm_out)\n",
    "            input_seq = lstm_out\n",
    "        if self.final_point_only:\n",
    "            lstm_out = torch.unsqueeze(lstm_out[:,-1,:], 1) # batch x seq_len x hidden\n",
    "        fc_out = self.fc(lstm_out)\n",
    "        if self.debug:\n",
    "            print(f\"lstm_out: {lstm_out}\")\n",
    "            print(f\"hn: {hn}\")\n",
    "            print(f\"cn: {cn}\")\n",
    "            print(f\"self.fc: {self.fc}\")\n",
    "            print(f\"fc_out: {fc_out}\")\n",
    "        return fc_out\n",
    "\n",
    "    \n",
    "def get_y_pred(pred_coeff, bottleneck_X):\n",
    "\n",
    "    MEF_preds = pred_coeff[:,:,0]\n",
    "    MDF_preds = pred_coeff[:,:,1]\n",
    "    delta_load = bottleneck_X[:,:,0]\n",
    "    delta_vre = bottleneck_X[:,:,1]\n",
    "    y_pred_demand = torch.mul(delta_load, MEF_preds)\n",
    "    y_pred_vre = torch.mul(delta_vre, MDF_preds)\n",
    "    y_pred = y_pred_vre + y_pred_demand\n",
    "    if pred_coeff.shape[-1] == 3:\n",
    "        # we are using a linear model with an intercept term\n",
    "        y_pred += pred_coeff[:,:,2]\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def mse_loss_l2_coeff_reg(pred_coeff, bottleneck_X, y, MEF_reg_weight, MDF_reg_weight):\n",
    "    \"\"\"\n",
    "    pred_coeff: batch x seq_len x output_dim\n",
    "    bottleneck_X: batch x seq_len x bottleneck_dim\n",
    "    y: batch x seq_len\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = get_y_pred(pred_coeff, bottleneck_X)\n",
    "\n",
    "    MEF_preds = pred_coeff[:,:,0]\n",
    "    MDF_preds = pred_coeff[:,:,1]\n",
    "\n",
    "    # Compute MEF regularization term (sum(MEF^2 + intercept if MEF < 0 for MEF in examples))\n",
    "    invalid_MEFs = torch.flatten(nn.functional.relu(-MEF_preds))  # keep negative MEFs and zero others\n",
    "    count_invalid_MEFs = torch.count_nonzero(invalid_MEFs)\n",
    "    MEF_reg_intercept = 4420  # based on an average value of -65 seen amongst invalids when trained without regularization\n",
    "    MEF_reg = torch.dot(invalid_MEFs, invalid_MEFs) + (count_invalid_MEFs * MEF_reg_intercept)\n",
    "\n",
    "    # Compute MDF regularization term (sum(MDF^2 + intercept if MDF > 0 for MDF in examples))\n",
    "    invalid_MDFs = torch.flatten(nn.functional.relu(MDF_preds))  # keep negative MEFs and zero others\n",
    "    count_invalid_MDFs = torch.count_nonzero(invalid_MDFs)\n",
    "    MDF_reg_intercept = 538  # based on an average value of +23 seen amongst invalids when trained without regularization\n",
    "    MDF_reg = torch.dot(invalid_MDFs, invalid_MDFs) + (count_invalid_MDFs * MDF_reg_intercept)\n",
    "\n",
    "    loss = nn.MSELoss()(y_pred, y) + (MEF_reg_weight * MEF_reg) + (MDF_reg_weight * MDF_reg)\n",
    "    return loss\n",
    "\n",
    "def mse_loss_l1_coeff_reg(pred_coeff, bottleneck_X, y, MEF_reg_weight, MDF_reg_weight):\n",
    "    \"\"\"\n",
    "    pred_coeff: batch x seq_len x output_dim\n",
    "    bottleneck_X: batch x seq_len x bottleneck_dim\n",
    "    y: batch x seq_len\n",
    "    \"\"\"\n",
    "    y_pred = get_y_pred(pred_coeff, bottleneck_X)\n",
    "\n",
    "    MEF_preds = pred_coeff[:,:,0]\n",
    "    MDF_preds = pred_coeff[:,:,1]\n",
    "\n",
    "    # Compute MEF regularization term (sum(MEF + intercept if MEF < 0 for MEF in examples))\n",
    "    invalid_MEFs = nn.functional.relu(-MEF_preds)  # keep negative MEFs and zero others\n",
    "    count_invalid_MEFs = torch.count_nonzero(invalid_MEFs)\n",
    "    MEF_reg_intercept = 66.5  # The average value seen amongst invalids when trained without regularization\n",
    "    MEF_reg = torch.sum(invalid_MEFs) + (count_invalid_MEFs * MEF_reg_intercept)\n",
    "\n",
    "    # Compute MDF regularization term (sum(MDF + intercept if MDF > 0 for MDF in examples))\n",
    "    invalid_MDFs = nn.functional.relu(MDF_preds)  # keep negative MEFs and zero others\n",
    "    count_invalid_MDFs = torch.count_nonzero(invalid_MDFs)\n",
    "    MDF_reg_intercept = 23.2  # The average value seen amongst invalids when trained without regularization\n",
    "    MDF_reg = torch.sum(invalid_MDFs) + (count_invalid_MDFs * MDF_reg_intercept)\n",
    "\n",
    "    loss = nn.MSELoss()(y_pred, y) + (MEF_reg_weight * MEF_reg) + (MDF_reg_weight * MDF_reg)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1bc93f",
   "metadata": {
    "id": "0a1bc93f"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2daa481",
   "metadata": {
    "id": "f2daa481"
   },
   "source": [
    "Helpers for printing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e34e76b6",
   "metadata": {
    "id": "e34e76b6"
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "738cbf27",
   "metadata": {
    "id": "738cbf27"
   },
   "outputs": [],
   "source": [
    "def plot_losses(train_losses, val_losses, plt_save_dir=None):\n",
    "    # plot loss vs epochs\n",
    "    fig, axs = plt.subplots(1,2)\n",
    "    axs[0].plot(train_losses[50:])\n",
    "    axs[0].set_title(\"Train Set\")\n",
    "    axs[0].set_ylabel('loss')\n",
    "    axs[0].set_xlabel('epoch')\n",
    "\n",
    "    axs[1].plot(val_losses[50:])\n",
    "    axs[1].set_title(\"Val Set\")\n",
    "    axs[1].set_ylabel('loss')\n",
    "    axs[1].set_xlabel('epoch')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if plt_save_dir:\n",
    "        fig.savefig(os.path.join(plt_save_dir, \"train_val_losses.png\"))\n",
    "\n",
    "# Probably delete this\n",
    "# def print_results(train_losses, train_pred_coeff, train_bottleneck_X, train_y,\n",
    "#                   val_losses, val_pred_coeff, val_bottleneck_X, val_y, \n",
    "#                   plt_save_dir=None):\n",
    "#     # plot loss vs epochs\n",
    "#     fig, axs = plt.subplots(1,2)\n",
    "#     axs[0].plot(train_losses[1:])\n",
    "#     axs[0].set_title(\"Train Set\")\n",
    "#     axs[0].set_ylabel('loss')\n",
    "#     axs[0].set_xlabel('epoch')\n",
    "\n",
    "#     axs[1].plot(val_losses[1:])\n",
    "#     axs[1].set_title(\"Val Set\")\n",
    "#     axs[1].set_ylabel('loss')\n",
    "#     axs[1].set_xlabel('epoch')\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     if plt_save_dir:\n",
    "#         fig.savefig(f\"{plt_save_dir}/train_val_losses.png\") \n",
    "\n",
    "#     train_y_pred = get_y_pred(train_pred_coeff, train_bottleneck_X)\n",
    "#     val_y_pred = get_y_pred(val_pred_coeff, val_bottleneck_X)\n",
    "\n",
    "#     # count number of invalid values predicted\n",
    "#     invalid_train_MEFs, invalid_train_MDFs = get_count_invalid_preds(train_pred_coeff)\n",
    "#     invalid_val_MEFs, invalid_val_MDFs = get_count_invalid_preds(val_pred_coeff)\n",
    "\n",
    "#     # calculate performance metrics\n",
    "#     train_error = train_y_pred - train_y\n",
    "#     print(\"Train Set:\")\n",
    "#     print(f\"\\tMean Emissions Change = {torch.mean(torch.abs(train_y)).item():.2f}\")\n",
    "#     print(f\"\\tMean Error = {torch.mean(torch.abs(train_error)).item():.2f}\")\n",
    "#     print(f\"\\tInvalid MEFs,MDFs = {invalid_train_MEFs},{invalid_train_MDFs}\")\n",
    "#     print(f\"\\tR Squared = {r2_score(train_y.cpu().detach().numpy(), train_y_pred.cpu().detach().numpy()):.4f}\")\n",
    "    \n",
    "#     val_error = val_y_pred - val_y\n",
    "#     print(\"Val Set:\")\n",
    "#     print(f\"\\tMean Emissions Change = {torch.mean(torch.abs(val_y)).item():.2f}\")\n",
    "#     print(f\"\\tMean Error = {torch.mean(torch.abs(val_error)).item():.2f}\")\n",
    "#     print(f\"\\tInvalid MEFs,MDFs = {invalid_val_MEFs},{invalid_val_MDFs}\")\n",
    "#     print(f\"\\tR Squared = {r2_score(val_y.cpu().detach().numpy(), val_y_pred.cpu().detach().numpy()):.4f}\")\n",
    "    \n",
    "def get_r_squared(pred_coeff, bottleneck_X, y):\n",
    "    y_pred = get_y_pred(pred_coeff, bottleneck_X)\n",
    "    # only one element in sequence is being predicted, return single R2\n",
    "    if y.shape[-1] == 1:\n",
    "        return r2_score(y.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "    # more than one elt in seq being predicted, return an R2 for each position that we could evaluate at\n",
    "    else:\n",
    "        return [r2_score(y_i, y_pred_i) for y_i, y_pred_i in \\\n",
    "                zip(y.permute(1,0).cpu().detach().numpy(),\n",
    "                    y_pred.permute(1,0).cpu().detach().numpy())]\n",
    "\n",
    "def get_mean_abs_err(pred_coeff, bottleneck_X, y):\n",
    "    y_pred = get_y_pred(pred_coeff, bottleneck_X)\n",
    "    # only one element in sequence is being predicted, return single MAE\n",
    "    if y.shape[-1] == 1:\n",
    "        return mean_absolute_error(y.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "    # more than one elt in seq being predicted, return an MAE for each position that we could evaluate at\n",
    "    else:\n",
    "        return [mean_absolute_error(y_i, y_pred_i) for y_i, y_pred_i in \\\n",
    "                zip(y.permute(1,0).cpu().detach().numpy(),\n",
    "                    y_pred.permute(1,0).cpu().detach().numpy())]\n",
    "\n",
    "def get_count_invalid_preds(pred_coeff):\n",
    "    count_neg_MEFs = torch.sum(pred_coeff[:,:,0] <= 0).item()  # MEF must be greater than 0\n",
    "    count_pos_MDFs = torch.sum(pred_coeff[:,:,1] > 0).item()  # MDF must be less than or equal to 0\n",
    "    return count_neg_MEFs, count_pos_MDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df07382",
   "metadata": {
    "id": "9df07382"
   },
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "R23-ZIyRwanX",
   "metadata": {
    "id": "R23-ZIyRwanX"
   },
   "outputs": [],
   "source": [
    "def train_model_with_params_batched(train_X, val_X, train_bottleneck_X, val_bottleneck_X, train_y, val_y,  # data\n",
    "                            input_size, hidden_size, output_size, final_point_only, num_layers, dropout,  # model settings\n",
    "                            learning_rate, weight_decay,  # optimizer settings\n",
    "                            loss_function, MEF_reg_weight, MDF_reg_weight,  # loss function settings\n",
    "                            model_dir_prefix=None, batch_size=None, epochs=10000, # train process settings\n",
    "                            print_freq=1000, min_save_r2=.87, max_save_mae=150000):  # train process settings\n",
    "\n",
    "    if not batch_size:\n",
    "        batch_size = len(train_X)\n",
    "\n",
    "    # if predicting final point in sequence only, keep only those corresponding points\n",
    "    # in the bottleneck_X and y arrays\n",
    "    if final_point_only:\n",
    "        train_bottleneck_X = torch.unsqueeze(train_bottleneck_X[:,-1,:], 1)\n",
    "        val_bottleneck_X = torch.unsqueeze(val_bottleneck_X[:,-1,:], 1)\n",
    "        train_y = torch.unsqueeze(train_y[:,-1], 1)\n",
    "        val_y = torch.unsqueeze(val_y[:,-1], 1)\n",
    "\n",
    "    # create model and optimizer\n",
    "    model = LSTM(input_size, hidden_size, output_size, final_point_only, num_layers, dropout)\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    # Set up folder where model and model info will be saved\n",
    "    model_dir = model_save_dir\n",
    "    if model_dir_prefix:\n",
    "        model_dir = os.path.join(model_dir, model_dir_prefix)\n",
    "    model_dir = os.path.join(model_dir, str(datetime.now().strftime('%Y_%m_%d-%I_%M_%S_%p')))\n",
    "    Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # log experiment settings\n",
    "    settings_str = \"Model Settings:\"\n",
    "    settings_str += f\"\\n\\t{input_size=}\\n\\t{hidden_size=}\\n\\t{output_size=}\\n\\t{final_point_only=}\\n\\t{num_layers=}\\n\\t{dropout=}\"\n",
    "    settings_str += \"\\nOptimizer Settings:\"\n",
    "    settings_str += f\"\\n\\t{learning_rate=}\\n\\t{weight_decay=}\"\n",
    "    settings_str += \"\\nLoss Function Settings:\"\n",
    "    settings_str += f\"\\n\\t{loss_function=}\\n\\t{MEF_reg_weight=}\\n\\t{MDF_reg_weight=}\"\n",
    "    settings_str += \"\\nTrain Process Settings:\"\n",
    "    settings_str += f\"\\n\\t{batch_size=}\\n\\t{epochs=}\\n\\t{min_save_r2=}\\n\\t{max_save_mae=}\"\n",
    "    settings_str += f\"\\nFeatures: {', '.join(feature_cols)}\"\n",
    "    print(settings_str)\n",
    "    with open(os.path.join(model_dir, \"experiment_settings.txt\"), 'w+') as f:\n",
    "        f.write(settings_str)\n",
    "\n",
    "    # set up vars for keeping track of stats of best-seen models\n",
    "    best_r2 = -np.inf\n",
    "    best_r2_epoch = None\n",
    "    best_mae = np.inf\n",
    "    best_mae_epoch = None\n",
    "    best_r2_model = {\"r2\": -np.inf}\n",
    "    best_mae_model = {\"mae\": np.inf}\n",
    "    if not final_point_only:\n",
    "        best_r2_any_point = -np.inf\n",
    "        best_r2_any_point_list = None\n",
    "        best_mae_any_point = np.inf\n",
    "        best_mae_any_point_list = None\n",
    "    \n",
    "    # train/eval loop\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    batches_per_epoch = int(np.ceil(len(train_X) / batch_size))\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        if batches_per_epoch > 1:\n",
    "            shuffle_perm = torch.randperm(len(train_X))\n",
    "            train_X = train_X[shuffle_perm]\n",
    "            train_bottleneck_X = train_bottleneck_X[shuffle_perm]\n",
    "            train_y = train_y[shuffle_perm]\n",
    "\n",
    "        # tell model we are training\n",
    "        model.train()\n",
    "        # make updates based on each batch in training data\n",
    "        for batch in range(batches_per_epoch):\n",
    "            batch_start, batch_end = batch * batch_size, (batch + 1) * batch_size\n",
    "            batch_train_X = train_X[batch_start: batch_end]\n",
    "            batch_train_bottleneck_X = train_bottleneck_X[batch_start: batch_end]\n",
    "            batch_train_y = train_y[batch_start: batch_end]\n",
    "        \n",
    "            batch_train_pred_coeff = model(batch_train_X.float())\n",
    "            batch_train_loss = loss_function(batch_train_pred_coeff, batch_train_bottleneck_X, batch_train_y, MEF_reg_weight, MDF_reg_weight)\n",
    "            model.zero_grad()\n",
    "            batch_train_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # tell model we are evaluating\n",
    "        model.eval()\n",
    "\n",
    "        # re-run on training data to get current train loss for the epoch\n",
    "        train_pred_coeff = model(train_X.float())\n",
    "        train_loss = loss_function(train_pred_coeff, train_bottleneck_X, train_y, MEF_reg_weight, MDF_reg_weight)\n",
    "        train_losses.append(train_loss.item())\n",
    "\n",
    "        # run on val data to evaluate how we are doing\n",
    "        val_pred_coeff = model(val_X.float())\n",
    "        val_loss = loss_function(val_pred_coeff, val_bottleneck_X, val_y, MEF_reg_weight, MDF_reg_weight)\n",
    "        val_losses.append(val_loss.item())\n",
    "        val_r2 = get_r_squared(val_pred_coeff, val_bottleneck_X, val_y)\n",
    "        val_mae = get_mean_abs_err(val_pred_coeff, val_bottleneck_X, val_y)\n",
    "        if not final_point_only:\n",
    "            val_r2_list = val_r2\n",
    "            val_mae_list = val_mae\n",
    "            # evaluate on last point in sequence only\n",
    "            val_r2 = val_r2[-1] \n",
    "            val_mae = val_mae[-1]\n",
    "            # update best seen at any point in sequence\n",
    "            val_r2_any_point = max(val_r2_list)\n",
    "            if val_r2_any_point > best_r2_any_point:\n",
    "                best_r2_any_point = val_r2_any_point\n",
    "                best_r2_any_point_list = val_r2_list\n",
    "            val_mae_any_point = min(val_mae_list) \n",
    "            if val_mae_any_point < best_mae_any_point:\n",
    "                best_mae_any_point = val_mae_any_point\n",
    "                best_mae_any_point_list = val_mae_list\n",
    "\n",
    "        # always keep best r2 and mae updated\n",
    "        if val_r2 > best_r2:\n",
    "            best_r2 = val_r2\n",
    "            best_r2_epoch = epoch\n",
    "        if val_mae < best_mae:\n",
    "            best_mae = val_mae\n",
    "            best_mae_epoch = epoch\n",
    "\n",
    "        # check if we should save best r2 model\n",
    "        if val_r2 > max(best_r2_model[\"r2\"], min_save_r2):\n",
    "            # only continue with saving if this model has no invalids\n",
    "            if sum(get_count_invalid_preds(val_pred_coeff))==0 and sum(get_count_invalid_preds(train_pred_coeff))==0:\n",
    "                # update best-r2-model stats\n",
    "                best_r2_model[\"r2\"] = val_r2\n",
    "                best_r2_model[\"epoch\"] = epoch\n",
    "                best_r2_model[\"mae\"] = val_mae\n",
    "                if not final_point_only:\n",
    "                    best_r2_model[\"seq-wise-r2\"] = val_r2_list\n",
    "                    best_r2_model[\"seq-wise-mae\"] = val_mae_list\n",
    "                # delete prev best-r2-model unless best-mae-model still points to it\n",
    "                if \"save_path\" in best_r2_model \\\n",
    "                and (\"save_path\" not in best_mae_model \\\n",
    "                or best_r2_model[\"save_path\"] != best_mae_model[\"save_path\"]):\n",
    "                    Path(best_r2_model[\"save_path\"]).unlink() # delete prev-best model\n",
    "                model_save_name = f\"epoch={epoch},r2={val_r2:.4f},mae={int(val_mae)},Invalids=0.pth\"\n",
    "                save_model_path = os.path.join(model_dir, model_save_name)\n",
    "                best_r2_model[\"save_path\"] = save_model_path\n",
    "                torch.save(model.state_dict(), save_model_path)\n",
    "\n",
    "        # check if we should save best mae model\n",
    "        if val_mae < min(best_mae_model[\"mae\"], max_save_mae):\n",
    "            # if we already saved best-r2-model on this round, then that model is our best mae model\n",
    "            if epoch in best_r2_model and best_r2_model[\"epoch\"] == epoch:\n",
    "                best_mae_model[\"r2\"] = val_r2\n",
    "                best_mae_model[\"epoch\"] = epoch\n",
    "                best_mae_model[\"mae\"] = val_mae\n",
    "                if not final_point_only:\n",
    "                    best_mae_model[\"seq-wise-r2\"] = val_r2_list\n",
    "                    best_mae_model[\"seq-wise-mae\"] = val_mae_list\n",
    "                # delete prev best-mae-model\n",
    "                if \"save_path\" in best_mae_model:\n",
    "                    Path(best_mae_model[\"save_path\"]).unlink() # delete prev-best model\n",
    "                best_mae_model[\"save_path\"] = best_r2_model[\"save_path\"]\n",
    "            # Otherwise need to check again if this model has no invalids\n",
    "            elif sum(get_count_invalid_preds(val_pred_coeff))==0 and sum(get_count_invalid_preds(train_pred_coeff))==0:\n",
    "                # update best-mae-model stats\n",
    "                best_mae_model[\"r2\"] = val_r2\n",
    "                best_mae_model[\"epoch\"] = epoch\n",
    "                best_mae_model[\"mae\"] = val_mae\n",
    "                if not final_point_only:\n",
    "                    best_mae_model[\"seq-wise-r2\"] = val_r2_list\n",
    "                    best_mae_model[\"seq-wise-mae\"] = val_mae_list\n",
    "                # delete prev best-mae-model unless best-r2-model still points to it\n",
    "                if \"save_path\" in best_mae_model \\\n",
    "                and (\"save_path\" not in best_r2_model \\\n",
    "                or best_r2_model[\"save_path\"] != best_mae_model[\"save_path\"]):\n",
    "                    Path(best_mae_model[\"save_path\"]).unlink() # delete prev-best model\n",
    "                model_save_name = f\"epoch={epoch},r2={val_r2:.4f},mae={int(val_mae)},Invalids=0.pth\"\n",
    "                save_model_path = os.path.join(model_dir, model_save_name)\n",
    "                best_mae_model[\"save_path\"] = save_model_path\n",
    "                torch.save(model.state_dict(), save_model_path)\n",
    "\n",
    "        # print performance info every so often\n",
    "        if epoch % print_freq == 0:\n",
    "            invalid_train_MEFs, invalid_train_MDFs = get_count_invalid_preds(train_pred_coeff)\n",
    "            invalid_val_MEFs, invalid_val_MDFs = get_count_invalid_preds(val_pred_coeff)\n",
    "            train_r2 = get_r_squared(train_pred_coeff, train_bottleneck_X, train_y)\n",
    "            if not final_point_only:\n",
    "                # evaluate on last point in sequence only\n",
    "                train_r2 = train_r2[-1] \n",
    "            print(f\"[Epoch {epoch}]\")\n",
    "            print(f\"\\tTrain Set: Loss={train_loss.item():.3e}, R Squared={train_r2:.4f}, Invalid MEFs={invalid_train_MEFs}, Invalid MDFs={invalid_train_MDFs}\")\n",
    "            print(f\"\\tVal Set: Loss={val_loss.item():.3e}, R Squared={val_r2:.4f}, Invalid MEFs={invalid_val_MEFs}, Invalid MDFs={invalid_val_MDFs}\")\n",
    "\n",
    "        # stop if we aren't improving after 10k epochs\n",
    "        if best_r2_epoch and epoch > 10000 + best_r2_epoch:\n",
    "            print(\"Early stopping as we haven't made an improvement on validation set in 10,000 epochs.\")\n",
    "            break\n",
    "    \n",
    "    plot_losses(train_losses, val_losses, model_dir)\n",
    "\n",
    "    results_str = f\"Best R Squared seen on epoch {best_r2_epoch}: {best_r2:.4f}\"\n",
    "    results_str += f\"\\nBest MAE seen on epoch {best_mae_epoch}: {best_mae:.2f}\"\n",
    "    results_str += f\"\\nBest-R2-model with R2 above {min_save_r2=} and 0 invalid coefficients predicted on train/test sets:\"\n",
    "    if \"save_path\" not in best_r2_model:\n",
    "        results_str += f\"\\n\\tNo such model was encountered\"\n",
    "    else:\n",
    "        results_str += f\"\\n\\tValidation R2: {best_r2_model['r2']:.4f}\"\n",
    "        results_str += f\"\\n\\tValidation MAE: {best_r2_model['mae']:.2f}\"\n",
    "        if not final_point_only:\n",
    "            r2_str_list = [f\"{val:.4f}\" for val in best_r2_model['seq-wise-r2']]\n",
    "            results_str += f\"\\n\\tValidation sequence-wise-R2: {r2_str_list}\"\n",
    "            mae_str_list = [f\"{val:.2f}\" for val in best_r2_model['seq-wise-mae']]\n",
    "            results_str += f\"\\n\\tValidation sequence-wise-MAE: {mae_str_list}\"\n",
    "        results_str += f\"\\n\\tEpoch seen: {best_r2_model['epoch']}\"\n",
    "        results_str += f\"\\n\\tModel file: {best_r2_model['save_path'].split('/')[-1]}\"\n",
    "    results_str += f\"\\nBest-MAE-model with MAE below {max_save_mae=} and 0 invalid coefficients predicted on train/test sets:\"\n",
    "    if \"save_path\" not in best_mae_model:\n",
    "        results_str += f\"\\n\\tNo such model was encountered\"\n",
    "    else:\n",
    "        results_str += f\"\\n\\tValidation R2: {best_mae_model['r2']:.4f}\"\n",
    "        results_str += f\"\\n\\tValidation MAE: {best_mae_model['mae']:.2f}\"\n",
    "        if not final_point_only:\n",
    "            r2_str_list = [f\"{val:.4f}\" for val in best_mae_model['seq-wise-r2']]\n",
    "            results_str += f\"\\n\\tValidation sequence-wise-R2: {r2_str_list}\"\n",
    "            mae_str_list = [f\"{val:.2f}\" for val in best_mae_model['seq-wise-mae']]\n",
    "            results_str += f\"\\n\\tValidation sequence-wise-MAE: {mae_str_list}\"\n",
    "        results_str += f\"\\n\\tEpoch seen: {best_mae_model['epoch']}\"\n",
    "        results_str += f\"\\n\\tModel file: {best_mae_model['save_path'].split('/')[-1]}\"\n",
    "    if not final_point_only:\n",
    "        results_str += f\"\\nSequence-wise-R2 with the highest R2 at any point in the sequence of {best_r2_any_point:.4f}:\"\n",
    "        r2_str_list = [f\"{val:.4f}\" for val in best_r2_any_point_list]\n",
    "        results_str += f\"\\n\\t{r2_str_list}\"\n",
    "        results_str += f\"\\nSequence-wise-MAE with the lowest MAE at any point in the sequence of {best_mae_any_point:.2f}:\"\n",
    "        mae_str_list = [f\"{val:.2f}\" for val in best_mae_any_point_list]\n",
    "        results_str += f\"\\n\\t{mae_str_list}\"\n",
    "\n",
    "    print(results_str)\n",
    "    with open(os.path.join(model_dir, \"results.txt\"), 'w+') as f:\n",
    "        f.write(results_str)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "084cdb90",
   "metadata": {
    "id": "084cdb90"
   },
   "outputs": [],
   "source": [
    "# def train_model_with_params(train_X, val_X, train_bottleneck_X, val_bottleneck_X, train_y, val_y,  # data\n",
    "#                             input_size, hidden_size, output_size, final_point_only, num_layers, dropout,  # model settings\n",
    "#                             learning_rate, weight_decay,  # optimizer settings\n",
    "#                             loss_function, MEF_reg_weight, MDF_reg_weight,  # loss function settings\n",
    "#                             model_dir_prefix=None, epochs=10000, print_freq=1000, min_save_r2=.87):  # train process settings\n",
    "\n",
    "#     # if predicting final point in sequence only, keep only those corresponding points\n",
    "#     # in the bottleneck_X and y arrays\n",
    "#     if final_point_only:\n",
    "#         train_bottleneck_X = torch.unsqueeze(train_bottleneck_X[:,-1,:], 1)\n",
    "#         val_bottleneck_X = torch.unsqueeze(val_bottleneck_X[:,-1,:], 1)\n",
    "#         train_y = torch.unsqueeze(train_y[:,-1], 1)\n",
    "#         val_y = torch.unsqueeze(val_y[:,-1], 1)\n",
    "\n",
    "#     # create model and optimizer\n",
    "#     model = LSTM(input_size, hidden_size, output_size, final_point_only, num_layers, dropout)\n",
    "#     model.to(device)\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "#     # Set up folder where model and model info will be saved\n",
    "#     model_dir = model_save_dir\n",
    "#     if model_dir_prefix:\n",
    "#         model_dir += f\"/{model_dir_prefix}\"\n",
    "#     model_dir += f\"/{datetime.now().strftime('%Y_%m_%d-%I:%M:%S_%p')}\"\n",
    "#     Path(model_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "#     # log experiment settings\n",
    "#     settings_str = \"Model Settings:\"\n",
    "#     settings_str += f\"\\n\\t{input_size=}\\n\\t{hidden_size=}\\n\\t{output_size=}\\n\\t{final_point_only=}\\n\\t{num_layers=}\\n\\t{dropout=}\"\n",
    "#     settings_str += \"\\nOptimizer Settings:\"\n",
    "#     settings_str += f\"\\n\\t{learning_rate=}\\n\\t{weight_decay=}\"\n",
    "#     settings_str += \"\\nLoss Function Settings:\"\n",
    "#     settings_str += f\"\\n\\t{loss_function=}\\n\\t{MEF_reg_weight=}\\n\\t{MDF_reg_weight=}\"\n",
    "#     settings_str += \"\\nTrain Process Settings:\"\n",
    "#     settings_str += f\"\\n\\t{epochs=}\\n\\t{min_save_r2=}\"\n",
    "#     settings_str += f\"\\nFeatures: {', '.join(feature_cols)}\"\n",
    "#     print(settings_str)\n",
    "#     with open(f\"{model_dir}/experiment_settings.txt\", 'w+') as f:\n",
    "#         f.write(settings_str)\n",
    "\n",
    "#     best_r2 = -np.inf \n",
    "#     best_epoch = None\n",
    "#     best_model_mae = -np.inf\n",
    "#     save_model_path = None\n",
    "#     last_save_epoch = None\n",
    "#     last_save_r2 = -np.inf\n",
    "    \n",
    "#     train_losses = []\n",
    "#     val_losses = []\n",
    "#     for epoch in tqdm(range(epochs)):\n",
    "#         # tell model we are training\n",
    "#         model.train()\n",
    "#         train_pred_coeff = model(train_X.float())\n",
    "#         train_loss = loss_function(train_pred_coeff, train_bottleneck_X, train_y, MEF_reg_weight, MDF_reg_weight)\n",
    "#         train_losses.append(train_loss.item())\n",
    "        \n",
    "#         # tell model we are evaluating\n",
    "#         model.eval()\n",
    "#         val_pred_coeff = model(val_X.float())\n",
    "#         val_loss = loss_function(val_pred_coeff, val_bottleneck_X, val_y, MEF_reg_weight, MDF_reg_weight)\n",
    "#         val_losses.append(val_loss.item())\n",
    "#         val_r2 = get_r_squared(val_pred_coeff, val_bottleneck_X, val_y)\n",
    "\n",
    "#         # always keep best r2 updated\n",
    "#         if val_r2 > best_r2:\n",
    "#             best_r2 = val_r2\n",
    "#             best_model_mae = get_mean_abs_err(val_pred_coeff, val_bottleneck_X, val_y)\n",
    "#             best_epoch = epoch\n",
    "#         # check if we should save... we need good enough r2 and no invalids\n",
    "#         if val_r2 > max(last_save_r2, min_save_r2):\n",
    "#             if sum(get_count_invalid_preds(val_pred_coeff))==0:\n",
    "#                 # also check training invalids... Let's recompute with eval mode\n",
    "#                 model.eval()\n",
    "#                 eval_mode_train_preds=model(train_X.float()).cpu()\n",
    "#                 if sum(get_count_invalid_preds(eval_mode_train_preds))==0:\n",
    "#                     if save_model_path:\n",
    "#                         Path(save_model_path).unlink() # delete prev-best model\n",
    "#                     model_save_name = f\"epoch={epoch},r2={val_r2:.4f},Invalids=0.pth\"\n",
    "#                     save_model_path = f\"{model_dir}/{model_save_name}\"\n",
    "#                     torch.save(model.state_dict(), save_model_path)\n",
    "#                     last_save_epoch = epoch\n",
    "#                     last_save_r2 = val_r2\n",
    "\n",
    "#         if epoch % print_freq == 0:\n",
    "#             invalid_train_MEFs, invalid_train_MDFs = get_count_invalid_preds(train_pred_coeff)\n",
    "#             invalid_val_MEFs, invalid_val_MDFs = get_count_invalid_preds(val_pred_coeff)\n",
    "#             train_r2 = get_r_squared(train_pred_coeff, train_bottleneck_X, train_y)\n",
    "#             print(f\"[Epoch {epoch}]\")\n",
    "#             print(f\"\\tTrain Set: Loss={train_loss.item():.3e}, R Squared={train_r2:.4f}, Invalid MEFs={invalid_train_MEFs}, Invalid MDFs={invalid_train_MDFs}\")\n",
    "#             print(f\"\\tVal Set: Loss={val_loss.item():.3e}, R Squared={val_r2:.4f}, Invalid MEFs={invalid_val_MEFs}, Invalid MDFs={invalid_val_MDFs}\")\n",
    "\n",
    "#         model.zero_grad()\n",
    "#         train_loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         # stop if we aren't improving after 10k epochs\n",
    "#         if best_epoch and epoch > 10000 + best_epoch:\n",
    "#             print(\"Early stopping as we haven't made an improvement on validation set in 10,000 epochs.\")\n",
    "#             break\n",
    "    \n",
    "#     print_results(train_losses, train_pred_coeff, train_bottleneck_X, train_y,\n",
    "#                   val_losses, val_pred_coeff, val_bottleneck_X, val_y, model_dir)\n",
    "#     print(f\"best R Squared seen on epoch {best_epoch}: {best_r2:.4f}\")\n",
    "#     if save_model_path:\n",
    "#         print(f\"best R Squared with no invalids predicted in train/val seen on epoch {last_save_epoch}: {last_save_r2:.4f}\")\n",
    "#         with open(f\"{save_model_path[:-4]}.results.txt\", 'w+') as f:\n",
    "#             f.write(\"Val Set:\")\n",
    "#             f.write(f\"\\tMean Absolute Error={best_model_mae:.2f}\")\n",
    "#             f.write(f\"\\tR Squared={best_r2:.4f}\")\n",
    "#     else:\n",
    "#         print(f\"No model was saved because no model that had no train/val invalids reached {min_save_r2} validation R2.\")\n",
    "        \n",
    "#     return save_model_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vfcTBVn9FrR-",
   "metadata": {
    "id": "vfcTBVn9FrR-"
   },
   "source": [
    "### param tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "NdIOFfthFwW0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "48f79cf624ea41229db24af7f7307eaa",
      "018f158461264820a43037233dc3843d",
      "5ce0b73fc6f843138c8b76f290562c69",
      "5d58cbdd7b944e99a9a24d2f7c9d3948",
      "1ccca095afed40f3a7d93abf2c94749b",
      "90ee2656eb3e4bd5a0d1189cac2d521c",
      "138722bc77c3400389ef616905904eaf",
      "7331c03842214571a355d32dc4f98865",
      "163dbaf1211a44d39d2faf30e2509295",
      "843889c691d04f938ad4bfdf5a4f3a6b",
      "05c854c5dda546acabb9da4ddad5b0ce"
     ]
    },
    "id": "NdIOFfthFwW0",
    "outputId": "b6647c26-ddca-4ece-b0c1-b6bb832d8706",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Settings:\n",
      "\tinput_size=4\n",
      "\thidden_size=32\n",
      "\toutput_size=3\n",
      "\tfinal_point_only=True\n",
      "\tnum_layers=4\n",
      "\tdropout=0.5\n",
      "Optimizer Settings:\n",
      "\tlearning_rate=0.003\n",
      "\tweight_decay=0.01\n",
      "Loss Function Settings:\n",
      "\tloss_function=<function mse_loss_l1_coeff_reg at 0x000002EB7A366820>\n",
      "\tMEF_reg_weight=10000000.0\n",
      "\tMDF_reg_weight=10000000.0\n",
      "Train Process Settings:\n",
      "\tbatch_size=2048\n",
      "\tepochs=1500\n",
      "\tmin_save_r2=0.86\n",
      "\tmax_save_mae=150000\n",
      "Features: Load, VRE, Hour, Day_of_Year\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bde669a5dd479cb29f94570df2dbf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0]\n",
      "\tTrain Set: Loss=3.039e+11, R Squared=0.0013, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.048e+11, R Squared=0.0012, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 50]\n",
      "\tTrain Set: Loss=5.371e+10, R Squared=0.8235, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=5.592e+10, R Squared=0.8168, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 100]\n",
      "\tTrain Set: Loss=4.328e+10, R Squared=0.8578, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=4.515e+10, R Squared=0.8521, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 150]\n",
      "\tTrain Set: Loss=4.092e+10, R Squared=0.8655, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=4.267e+10, R Squared=0.8602, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 200]\n",
      "\tTrain Set: Loss=3.932e+10, R Squared=0.8708, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=4.122e+10, R Squared=0.8650, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 250]\n",
      "\tTrain Set: Loss=3.844e+10, R Squared=0.8737, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=4.109e+10, R Squared=0.8654, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 300]\n",
      "\tTrain Set: Loss=3.808e+10, R Squared=0.8749, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=4.077e+10, R Squared=0.8664, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 350]\n",
      "\tTrain Set: Loss=3.764e+10, R Squared=0.8763, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=4.025e+10, R Squared=0.8681, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 400]\n",
      "\tTrain Set: Loss=3.666e+10, R Squared=0.8795, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.952e+10, R Squared=0.8705, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 450]\n",
      "\tTrain Set: Loss=3.526e+10, R Squared=0.8841, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.816e+10, R Squared=0.8750, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 500]\n",
      "\tTrain Set: Loss=3.495e+10, R Squared=0.8851, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.790e+10, R Squared=0.8758, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 550]\n",
      "\tTrain Set: Loss=3.427e+10, R Squared=0.8874, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.797e+10, R Squared=0.8756, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 600]\n",
      "\tTrain Set: Loss=3.540e+10, R Squared=0.8837, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.851e+10, R Squared=0.8738, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 650]\n",
      "\tTrain Set: Loss=3.393e+10, R Squared=0.8885, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.747e+10, R Squared=0.8772, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 700]\n",
      "\tTrain Set: Loss=3.404e+10, R Squared=0.8881, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.766e+10, R Squared=0.8766, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 750]\n",
      "\tTrain Set: Loss=3.400e+10, R Squared=0.8883, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.730e+10, R Squared=0.8778, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 800]\n",
      "\tTrain Set: Loss=3.364e+10, R Squared=0.8894, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.728e+10, R Squared=0.8779, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 850]\n",
      "\tTrain Set: Loss=3.306e+10, R Squared=0.8913, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.738e+10, R Squared=0.8775, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 900]\n",
      "\tTrain Set: Loss=3.348e+10, R Squared=0.8900, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.788e+10, R Squared=0.8759, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 950]\n",
      "\tTrain Set: Loss=3.310e+10, R Squared=0.8912, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.731e+10, R Squared=0.8778, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 1000]\n",
      "\tTrain Set: Loss=3.323e+10, R Squared=0.8908, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.795e+10, R Squared=0.8757, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 1050]\n",
      "\tTrain Set: Loss=3.295e+10, R Squared=0.8917, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.695e+10, R Squared=0.8789, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 1100]\n",
      "\tTrain Set: Loss=3.297e+10, R Squared=0.8916, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.761e+10, R Squared=0.8768, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 1150]\n",
      "\tTrain Set: Loss=3.276e+10, R Squared=0.8923, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.712e+10, R Squared=0.8784, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 1200]\n",
      "\tTrain Set: Loss=3.239e+10, R Squared=0.8935, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.698e+10, R Squared=0.8788, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 1250]\n",
      "\tTrain Set: Loss=3.255e+10, R Squared=0.8930, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.737e+10, R Squared=0.8776, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 1300]\n",
      "\tTrain Set: Loss=3.231e+10, R Squared=0.8938, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.718e+10, R Squared=0.8782, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 1350]\n",
      "\tTrain Set: Loss=3.236e+10, R Squared=0.8936, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.713e+10, R Squared=0.8784, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 1400]\n",
      "\tTrain Set: Loss=3.248e+10, R Squared=0.8933, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.726e+10, R Squared=0.8779, Invalid MEFs=0, Invalid MDFs=0\n",
      "[Epoch 1450]\n",
      "\tTrain Set: Loss=3.222e+10, R Squared=0.8941, Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal Set: Loss=3.753e+10, R Squared=0.8770, Invalid MEFs=0, Invalid MDFs=0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R Squared seen on epoch 1481: 0.8801\n",
      "Best MAE seen on epoch 1162: 136792.83\n",
      "Best-R2-model with R2 above min_save_r2=0.86 and 0 invalid coefficients predicted on train/test sets:\n",
      "\tValidation R2: 0.8801\n",
      "\tValidation MAE: 137129.09\n",
      "\tEpoch seen: 1481\n",
      "\tModel file: C:\\Users\\nicklein\\Documents\\MEF-Regression\\lstm_models\\predict_final_in_seq4_BNs\\2022_12_09-06_26_37_PM\\epoch=1481,r2=0.8801,mae=137129,Invalids=0.pth\n",
      "Best-MAE-model with MAE below max_save_mae=150000 and 0 invalid coefficients predicted on train/test sets:\n",
      "\tValidation R2: 0.8796\n",
      "\tValidation MAE: 136792.83\n",
      "\tEpoch seen: 1162\n",
      "\tModel file: C:\\Users\\nicklein\\Documents\\MEF-Regression\\lstm_models\\predict_final_in_seq4_BNs\\2022_12_09-06_26_37_PM\\epoch=1162,r2=0.8796,mae=136792,Invalids=0.pth\n"
     ]
    }
   ],
   "source": [
    "train_set, val_set = data_sets[\"train\"], data_sets[\"val\"]      \n",
    "train_X, train_bottleneck_X, train_y = train_set[\"X\"], train_set[\"bottleneck_X\"], train_set[\"y\"]\n",
    "val_X, val_bottleneck_X, val_y = val_set[\"X\"], val_set[\"bottleneck_X\"], val_set[\"y\"]\n",
    "input_size = train_X.shape[-1]\n",
    "output_size = 3  # 3 means we have an intercept\n",
    "\n",
    "### Tune Params Below ###\n",
    "hidden_size = 32\n",
    "final_point_only = True\n",
    "num_layers = 4\n",
    "dropout = .5\n",
    "batch_size = 2048\n",
    "learning_rate = .003\n",
    "weight_decay = .01\n",
    "loss_function = mse_loss_l1_coeff_reg\n",
    "MEF_reg_weight, MDF_reg_weight = 1e7, 1e7\n",
    "model_dir_prefix = f\"predict_{'final' if final_point_only else 'all'}_in_seq4_BNs\"\n",
    "epochs = 1500\n",
    "min_save_r2 = .86\n",
    "max_save_mae = 150000\n",
    "print_freq=50\n",
    "# evaluate\n",
    "save_model_path = train_model_with_params_batched(train_X, val_X, train_bottleneck_X, val_bottleneck_X, train_y, val_y,  # data\n",
    "                            input_size, hidden_size, output_size, final_point_only, num_layers, dropout,  # model settings\n",
    "                            learning_rate, weight_decay,  # optimizer settings\n",
    "                            loss_function, MEF_reg_weight, MDF_reg_weight,  # loss function settings\n",
    "                            model_dir_prefix, batch_size, epochs, print_freq, min_save_r2, max_save_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "PqgcArQqy5cg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqgcArQqy5cg",
    "outputId": "331adb91-9c07-4dc2-c9c2-1a31eb78be79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14443, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8I8vfs5iyXIx",
   "metadata": {
    "id": "8I8vfs5iyXIx"
   },
   "outputs": [],
   "source": [
    "final_point_only = False\n",
    "train_set, val_set = data_sets[\"train\"], data_sets[\"val\"]      \n",
    "train_X, train_bottleneck_X, train_y = train_set[\"X\"], train_set[\"bottleneck_X\"], train_set[\"y\"]\n",
    "val_X, val_bottleneck_X, val_y = val_set[\"X\"], val_set[\"bottleneck_X\"], val_set[\"y\"]\n",
    "\n",
    "if final_point_only:\n",
    "    train_bottleneck_X = torch.unsqueeze(train_bottleneck_X[:,-1,:], 1)\n",
    "    val_bottleneck_X = torch.unsqueeze(val_bottleneck_X[:,-1,:], 1)\n",
    "    train_y = torch.unsqueeze(train_y[:,-1], 1)\n",
    "    val_y = torch.unsqueeze(val_y[:,-1], 1)\n",
    "\n",
    "model = LSTM(input_size, hidden_size, output_size, final_point_only, num_layers, dropout)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# tell model we are training\n",
    "model.train()\n",
    "train_pred_coeff = model(train_X.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bGdznlt7zJ2r",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bGdznlt7zJ2r",
    "outputId": "207c8495-187d-4e55-c83d-bc05fadfc645"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14443, 8, 3])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_coeff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "srAyNJOxJjAI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "srAyNJOxJjAI",
    "outputId": "3dcc6d12-8992-4223-edba-bbac4400fd39"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0821,  0.0328,  0.0419],\n",
       "        [-0.1009,  0.0313,  0.0490],\n",
       "        [-0.1116,  0.0303,  0.0497],\n",
       "        [-0.1230,  0.0308,  0.0537],\n",
       "        [-0.1195,  0.0267,  0.0574],\n",
       "        [-0.1183,  0.0274,  0.0567],\n",
       "        [-0.1202,  0.0226,  0.0591],\n",
       "        [-0.1184,  0.0256,  0.0556]], device='cuda:0',\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred_coeff[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "zP-F0bppzruY",
   "metadata": {
    "id": "zP-F0bppzruY"
   },
   "outputs": [],
   "source": [
    "y_pred = get_y_pred(train_pred_coeff, train_bottleneck_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "VJ3tQGYbz2AK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VJ3tQGYbz2AK",
    "outputId": "35bdb420-11e4-45a6-d95b-5f930b5e4a9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14443, 8])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "zLSWb4rz1hpy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zLSWb4rz1hpy",
    "outputId": "4dbd979b-6402-4944-e3a5-7b006d69a4ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14443, 8])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "g861CPnTKQGA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g861CPnTKQGA",
    "outputId": "40b8e9f9-7e8e-43e7-8b9b-c91484c86a3f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([104.5600,  93.8499,  66.5238,  31.8933,  -4.7518, -59.5235, -92.0250,\n",
       "         30.1953], device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "pobejekWKQD1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pobejekWKQD1",
    "outputId": "4419b41e-30d6-4946-9ae3-9b33c2fbe9d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-337029.7812, -243021.8281, -144846.7969,  -24776.5703,   49254.1367,\n",
       "          88759.6875, 1101974.1250, -860734.4375], device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "AyNTATP3zrYx",
   "metadata": {
    "id": "AyNTATP3zrYx"
   },
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()(y_pred, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0Hh3KyLA34rf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Hh3KyLA34rf",
    "outputId": "29025869-660b-4e2a-87b1-e8a0316f4f93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0439e+11, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7rNwHtGa1wX",
   "metadata": {
    "id": "d7rNwHtGa1wX"
   },
   "source": [
    "## Inference on all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "_aGp7ISVb0y8",
   "metadata": {
    "id": "_aGp7ISVb0y8"
   },
   "outputs": [],
   "source": [
    "## below we can load specific models instead of best one found in most recent experiment\n",
    "model_path= \"drive/MyDrive/NN_MEFs/lstm_models/predict_all_in_seq8/2022_12_08-12:36:39_AM/epoch=998,r2=0.8741,Invalids=0.pth\"\n",
    "\n",
    "train_set, val_set = data_sets[\"train\"], data_sets[\"val\"]      \n",
    "train_X, train_bottleneck_X, train_y = train_set[\"X\"], train_set[\"bottleneck_X\"], train_set[\"y\"]\n",
    "val_X, val_bottleneck_X, val_y = val_set[\"X\"], val_set[\"bottleneck_X\"], val_set[\"y\"]\n",
    "input_size = train_X.shape[-1]\n",
    "output_size = 3  # 3 means we have an intercept\n",
    "hidden_size = 32\n",
    "final_point_only = False\n",
    "num_layers = 1\n",
    "dropout = 0\n",
    "\n",
    "model = LSTM(input_size, hidden_size, output_size, final_point_only, num_layers, dropout)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "train_pred_coeff = model(train_X.float())\n",
    "val_pred_coeff = model(val_X.float())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "Xzu9Fu4wZ6ZD",
   "metadata": {
    "id": "Xzu9Fu4wZ6ZD"
   },
   "outputs": [],
   "source": [
    "train_y_pred = get_y_pred(train_pred_coeff, train_bottleneck_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4x-M_96gZ6P5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4x-M_96gZ6P5",
    "outputId": "919cad51-3c97-4c95-a955-ca1d7a019a53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14443, 8])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "W4G-XBQTZ6LF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W4G-XBQTZ6LF",
    "outputId": "73de7ee6-d58d-4348-8129-7d223a3059c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8834384493448952"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(train_y.cpu().detach().numpy(), train_y_pred.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "J93Aym-wZ6Ex",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J93Aym-wZ6Ex",
    "outputId": "4cd71904-4aea-4b94-f467-e4eb4dab89c0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8529343380942997,\n",
       " 0.8696363903200108,\n",
       " 0.8795923203147114,\n",
       " 0.8862990346813329,\n",
       " 0.8909820117950451,\n",
       " 0.8939545501303765,\n",
       " 0.8963344742449033,\n",
       " 0.897774475458195]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[r2_score(y, y_pred) for y, y_pred in \\\n",
    " zip(train_y.permute(1,0).cpu().detach().numpy(), train_y_pred.permute(1,0).cpu().detach().numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "EYBqgfGmc1QH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EYBqgfGmc1QH",
    "outputId": "4fc5e450-4bca-465f-8eee-7fcf5684453c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall val r2: 0.8741031307517685\n",
      "val r2 by sequence position:\n",
      "[0.8568319386070357, 0.8682907729195138, 0.8745469021399369, 0.8777426423604695, 0.8794796853834416, 0.8781586552040923, 0.8787055918233209, 0.8790688571549825]\n"
     ]
    }
   ],
   "source": [
    "val_y_pred = get_y_pred(val_pred_coeff, val_bottleneck_X)\n",
    "print(f\"overall val r2: {r2_score(val_y.cpu().detach().numpy(), val_y_pred.cpu().detach().numpy())}\")\n",
    "print(\"val r2 by sequence position:\")\n",
    "print([r2_score(y, y_pred) for y, y_pred in \\\n",
    " zip(val_y.permute(1,0).cpu().detach().numpy(), val_y_pred.permute(1,0).cpu().detach().numpy())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "S0Xum_K0c1Mi",
   "metadata": {
    "id": "S0Xum_K0c1Mi"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QqKvf2Q0c0-Y",
   "metadata": {
    "id": "QqKvf2Q0c0-Y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6DHacOOCZYoj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6DHacOOCZYoj",
    "outputId": "b7064058-d857-4b67-ba28-02d67b71d9ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Squared:\n",
      "\tTrain: 0.8921\n",
      "\tVal: 0.8805\n",
      "\tTest: 0.8755\n",
      "Mean Absolute Error:\n",
      "\tTrain: 131028.76\n",
      "\tVal: 140016.71\n",
      "\tTest: 139890.26\n",
      "Count Invalid Values Predicted:\n",
      "\tTrain: Invalid MEFs=0, Invalid MDFs=0\n",
      "\tVal: Invalid MEFs=0, Invalid MDFs=0\n",
      "\tTest: Invalid MEFs=0, Invalid MDFs=0\n"
     ]
    }
   ],
   "source": [
    "hidden_dims = [512,256]\n",
    "bias_term = True\n",
    "dropout_p = 0.5\n",
    "n_input = train_x.shape[1]\n",
    "\n",
    "\n",
    "model = get_model(n_input, hidden_dims, n_out, dropout_p)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(best_model_path))\n",
    "model.eval()\n",
    "\n",
    "train_pred_coeff = model(train_x.float()).cpu()\n",
    "val_pred_coeff = model(val_x.float()).cpu()\n",
    "test_pred_coeff = model(test_x.float()).cpu()\n",
    "\n",
    "print(\"R Squared:\")\n",
    "print(f\"\\tTrain: {get_r_squared(train_pred_coeff, CAISO_train, bias_term):.4f}\")\n",
    "print(f\"\\tVal: {get_r_squared(val_pred_coeff, CAISO_val, bias_term):.4f}\")\n",
    "print(f\"\\tTest: {get_r_squared(test_pred_coeff, CAISO_test, bias_term):.4f}\")\n",
    "print(\"Mean Absolute Error:\")\n",
    "print(f\"\\tTrain: {get_mean_abs_err(train_pred_coeff, CAISO_train, bias_term):.2f}\")\n",
    "print(f\"\\tVal: {get_mean_abs_err(val_pred_coeff, CAISO_val, bias_term):.2f}\")\n",
    "print(f\"\\tTest: {get_mean_abs_err(test_pred_coeff, CAISO_test, bias_term):.2f}\")\n",
    "print(\"Count Invalid Values Predicted:\")\n",
    "invalid_train_MEFs, invalid_train_MDFs = get_count_invalid_preds(train_pred_coeff)\n",
    "invalid_val_MEFs, invalid_val_MDFs = get_count_invalid_preds(val_pred_coeff)\n",
    "invalid_test_MEFs, invalid_test_MDFs = get_count_invalid_preds(test_pred_coeff)\n",
    "print(f\"\\tTrain: Invalid MEFs={invalid_train_MEFs}, Invalid MDFs={invalid_train_MDFs}\")\n",
    "print(f\"\\tVal: Invalid MEFs={invalid_val_MEFs}, Invalid MDFs={invalid_val_MDFs}\")\n",
    "print(f\"\\tTest: Invalid MEFs={invalid_test_MEFs}, Invalid MDFs={invalid_test_MDFs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fi3OLzVQPK_O",
   "metadata": {
    "id": "fi3OLzVQPK_O"
   },
   "source": [
    "### Put the MEFs and MDFs from all sets back together and in order into the original DF for viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uB50w20k_Iao",
   "metadata": {
    "id": "uB50w20k_Iao"
   },
   "outputs": [],
   "source": [
    "all_preds_w_timestamps = list(zip(CAISO_val.index, val_pred_coeff.detach().numpy())) \\\n",
    "                        + list(zip(CAISO_train.index, train_pred_coeff.detach().numpy())) \\\n",
    "                        + list(zip(CAISO_test.index, test_pred_coeff.detach().numpy()))\n",
    "all_preds_w_timestamps.sort(key=lambda pair: pair[0])\n",
    "all_preds_ordered = np.array([pair[1] for pair in all_preds_w_timestamps])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vHn1WJaZCXm2",
   "metadata": {
    "id": "vHn1WJaZCXm2"
   },
   "outputs": [],
   "source": [
    "all_MEFs_ordered = all_preds_ordered[:,0]\n",
    "all_MDFs_ordered = all_preds_ordered[:,1]\n",
    "all_intercepts_ordered = all_preds_ordered[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aDaE9gk8cX_g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aDaE9gk8cX_g",
    "outputId": "e18f47bf-7d0a-4621-9d5d-615c99f75149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole Data Set:\n",
      "\tMean Emissions Change = 413165.73\n",
      "\tR Squared = 0.8864\n",
      "\tMean Absolute Error = 134598.78\n"
     ]
    }
   ],
   "source": [
    "CAISO_Data.loc[:,\"MEF\"] = all_MEFs_ordered\n",
    "CAISO_Data.loc[:,\"MDF\"] = all_MDFs_ordered\n",
    "if bias_term:\n",
    "    CAISO_Data.loc[:,\"Intercept\"] = all_intercepts_ordered\n",
    "\n",
    "#calculate some error stuff. rn i am thinking R2 is the best measure of error\n",
    "d_emissions = CAISO_Data.loc[:,'MEF'] * CAISO_Data.loc[:,'delta_Load'] \\\n",
    "            + CAISO_Data.loc[:,'MDF'] * CAISO_Data.loc[:,'delta_VRE']\n",
    "if bias_term:\n",
    "    d_emissions += CAISO_Data.loc[:,\"Intercept\"]\n",
    "CAISO_Data.loc[:,'Predicted_delta_Total_CO2_Emissions'] = d_emissions\n",
    "CAISO_Data.loc[:,'Error']=CAISO_Data.loc[:,'Predicted_delta_Total_CO2_Emissions']-CAISO_Data.loc[:,'delta_Total_CO2_Emissions']\n",
    "CAISO_Data.loc[:,'%_Error']=np.abs(CAISO_Data.loc[:,'Error'])/np.abs(CAISO_Data.loc[:,'delta_Total_CO2_Emissions'])\n",
    "print(\"Whole Data Set:\")\n",
    "print(f\"\\tMean Emissions Change = {np.mean(np.abs(CAISO_Data['delta_Total_CO2_Emissions'])):.2f}\")\n",
    "print(f\"\\tR Squared = {r2_score(CAISO_Data['delta_Total_CO2_Emissions'], CAISO_Data['Predicted_delta_Total_CO2_Emissions']):.4f}\")\n",
    "print(f\"\\tMean Absolute Error = {mean_absolute_error(CAISO_Data['delta_Total_CO2_Emissions'], CAISO_Data['Predicted_delta_Total_CO2_Emissions']):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HLrBWNZifiaF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "HLrBWNZifiaF",
    "outputId": "5d4a38f3-9e47-4f9e-89cf-4d1c8a35cd42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-8a367649-fc32-4a72-9bd2-225f8c53ff14\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Load</th>\n",
       "      <th>Net Load</th>\n",
       "      <th>Total_CO2_Emissions</th>\n",
       "      <th>Total_SO2_Emissions</th>\n",
       "      <th>Total_NOX_Emissions</th>\n",
       "      <th>VRE</th>\n",
       "      <th>delta_Load</th>\n",
       "      <th>delta_Net_Load</th>\n",
       "      <th>delta_Total_CO2_Emissions</th>\n",
       "      <th>delta_Total_SO2_Emissions</th>\n",
       "      <th>...</th>\n",
       "      <th>Day_of_Week=3</th>\n",
       "      <th>Day_of_Week=4</th>\n",
       "      <th>Day_of_Week=5</th>\n",
       "      <th>Day_of_Week=6</th>\n",
       "      <th>MEF</th>\n",
       "      <th>MDF</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>Predicted_delta_Total_CO2_Emissions</th>\n",
       "      <th>Error</th>\n",
       "      <th>%_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01 00:00:00</th>\n",
       "      <td>22822.964472</td>\n",
       "      <td>20502.358502</td>\n",
       "      <td>5.103942e+06</td>\n",
       "      <td>425.327933</td>\n",
       "      <td>1632.821698</td>\n",
       "      <td>2320.593616</td>\n",
       "      <td>-1285.054865</td>\n",
       "      <td>-1255.110267</td>\n",
       "      <td>-337029.794143</td>\n",
       "      <td>-24.142180</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>370.729431</td>\n",
       "      <td>-350.030640</td>\n",
       "      <td>6396.021973</td>\n",
       "      <td>-459526.000872</td>\n",
       "      <td>-122496.206729</td>\n",
       "      <td>0.363458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 01:00:00</th>\n",
       "      <td>21879.620618</td>\n",
       "      <td>19606.836908</td>\n",
       "      <td>4.867578e+06</td>\n",
       "      <td>404.315852</td>\n",
       "      <td>1557.650531</td>\n",
       "      <td>2272.780097</td>\n",
       "      <td>-944.689268</td>\n",
       "      <td>-896.922625</td>\n",
       "      <td>-243021.833700</td>\n",
       "      <td>-21.594332</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>345.051025</td>\n",
       "      <td>-323.291504</td>\n",
       "      <td>6071.847168</td>\n",
       "      <td>-304454.710093</td>\n",
       "      <td>-61432.876394</td>\n",
       "      <td>0.252787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 02:00:00</th>\n",
       "      <td>21257.454020</td>\n",
       "      <td>19056.267637</td>\n",
       "      <td>4.723101e+06</td>\n",
       "      <td>383.695714</td>\n",
       "      <td>1496.197481</td>\n",
       "      <td>2201.182455</td>\n",
       "      <td>-614.641020</td>\n",
       "      <td>-545.206677</td>\n",
       "      <td>-144846.797503</td>\n",
       "      <td>-20.952957</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>323.416351</td>\n",
       "      <td>-301.258514</td>\n",
       "      <td>5678.250977</td>\n",
       "      <td>-172189.482236</td>\n",
       "      <td>-27342.684733</td>\n",
       "      <td>0.188770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 03:00:00</th>\n",
       "      <td>20974.800758</td>\n",
       "      <td>18871.418601</td>\n",
       "      <td>4.693112e+06</td>\n",
       "      <td>380.561848</td>\n",
       "      <td>1466.329836</td>\n",
       "      <td>2103.388502</td>\n",
       "      <td>-281.391674</td>\n",
       "      <td>-191.565227</td>\n",
       "      <td>-24776.569759</td>\n",
       "      <td>-2.164379</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>305.443024</td>\n",
       "      <td>-282.996887</td>\n",
       "      <td>5341.076660</td>\n",
       "      <td>-55190.639304</td>\n",
       "      <td>-30414.069545</td>\n",
       "      <td>1.227534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01 04:00:00</th>\n",
       "      <td>20327.083333</td>\n",
       "      <td>18012.666667</td>\n",
       "      <td>5.032423e+06</td>\n",
       "      <td>711.911968</td>\n",
       "      <td>2391.657870</td>\n",
       "      <td>2314.666667</td>\n",
       "      <td>30.416667</td>\n",
       "      <td>74.416667</td>\n",
       "      <td>49254.136541</td>\n",
       "      <td>69.703951</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>303.949066</td>\n",
       "      <td>-272.057770</td>\n",
       "      <td>5023.662109</td>\n",
       "      <td>26216.649928</td>\n",
       "      <td>-23037.486613</td>\n",
       "      <td>0.467727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  37 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a367649-fc32-4a72-9bd2-225f8c53ff14')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-8a367649-fc32-4a72-9bd2-225f8c53ff14 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-8a367649-fc32-4a72-9bd2-225f8c53ff14');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                             Load      Net Load  Total_CO2_Emissions  \\\n",
       "2019-01-01 00:00:00  22822.964472  20502.358502         5.103942e+06   \n",
       "2019-01-01 01:00:00  21879.620618  19606.836908         4.867578e+06   \n",
       "2019-01-01 02:00:00  21257.454020  19056.267637         4.723101e+06   \n",
       "2019-01-01 03:00:00  20974.800758  18871.418601         4.693112e+06   \n",
       "2019-01-01 04:00:00  20327.083333  18012.666667         5.032423e+06   \n",
       "\n",
       "                     Total_SO2_Emissions  Total_NOX_Emissions          VRE  \\\n",
       "2019-01-01 00:00:00           425.327933          1632.821698  2320.593616   \n",
       "2019-01-01 01:00:00           404.315852          1557.650531  2272.780097   \n",
       "2019-01-01 02:00:00           383.695714          1496.197481  2201.182455   \n",
       "2019-01-01 03:00:00           380.561848          1466.329836  2103.388502   \n",
       "2019-01-01 04:00:00           711.911968          2391.657870  2314.666667   \n",
       "\n",
       "                      delta_Load  delta_Net_Load  delta_Total_CO2_Emissions  \\\n",
       "2019-01-01 00:00:00 -1285.054865    -1255.110267             -337029.794143   \n",
       "2019-01-01 01:00:00  -944.689268     -896.922625             -243021.833700   \n",
       "2019-01-01 02:00:00  -614.641020     -545.206677             -144846.797503   \n",
       "2019-01-01 03:00:00  -281.391674     -191.565227              -24776.569759   \n",
       "2019-01-01 04:00:00    30.416667       74.416667               49254.136541   \n",
       "\n",
       "                     delta_Total_SO2_Emissions  ...  Day_of_Week=3  \\\n",
       "2019-01-01 00:00:00                 -24.142180  ...          False   \n",
       "2019-01-01 01:00:00                 -21.594332  ...          False   \n",
       "2019-01-01 02:00:00                 -20.952957  ...          False   \n",
       "2019-01-01 03:00:00                  -2.164379  ...          False   \n",
       "2019-01-01 04:00:00                  69.703951  ...          False   \n",
       "\n",
       "                     Day_of_Week=4  Day_of_Week=5  Day_of_Week=6         MEF  \\\n",
       "2019-01-01 00:00:00          False          False          False  370.729431   \n",
       "2019-01-01 01:00:00          False          False          False  345.051025   \n",
       "2019-01-01 02:00:00          False          False          False  323.416351   \n",
       "2019-01-01 03:00:00          False          False          False  305.443024   \n",
       "2019-01-01 04:00:00          False          False          False  303.949066   \n",
       "\n",
       "                            MDF    Intercept  \\\n",
       "2019-01-01 00:00:00 -350.030640  6396.021973   \n",
       "2019-01-01 01:00:00 -323.291504  6071.847168   \n",
       "2019-01-01 02:00:00 -301.258514  5678.250977   \n",
       "2019-01-01 03:00:00 -282.996887  5341.076660   \n",
       "2019-01-01 04:00:00 -272.057770  5023.662109   \n",
       "\n",
       "                     Predicted_delta_Total_CO2_Emissions          Error  \\\n",
       "2019-01-01 00:00:00                       -459526.000872 -122496.206729   \n",
       "2019-01-01 01:00:00                       -304454.710093  -61432.876394   \n",
       "2019-01-01 02:00:00                       -172189.482236  -27342.684733   \n",
       "2019-01-01 03:00:00                        -55190.639304  -30414.069545   \n",
       "2019-01-01 04:00:00                         26216.649928  -23037.486613   \n",
       "\n",
       "                      %_Error  \n",
       "2019-01-01 00:00:00  0.363458  \n",
       "2019-01-01 01:00:00  0.252787  \n",
       "2019-01-01 02:00:00  0.188770  \n",
       "2019-01-01 03:00:00  1.227534  \n",
       "2019-01-01 04:00:00  0.467727  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAISO_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XG2_fHd5fmAI",
   "metadata": {
    "id": "XG2_fHd5fmAI"
   },
   "outputs": [],
   "source": [
    "CAISO_Data.to_csv(f\"{best_model_dir}/CAISO_Data_2019_2021_NN_Ts.with_coeff_preds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uJWPn96SFkTa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uJWPn96SFkTa",
    "outputId": "1ee10191-30a4-4a58-f089-677458a2c182"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([val for val in CAISO_Data.loc[:,\"MEF\"] if val <=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89hutia2GEKj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "89hutia2GEKj",
    "outputId": "12d38d99-8e8d-41a8-b34a-00e3fc3201b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([val for val in CAISO_Data.loc[:,\"MEF\"] if val >600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F2PyvXRSGoiX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2PyvXRSGoiX",
    "outputId": "2bdc08c2-f712-4523-f1b7-d0dc015a8764"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "719.43835"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAISO_Data.loc[:,\"MEF\"].max()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "018f158461264820a43037233dc3843d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90ee2656eb3e4bd5a0d1189cac2d521c",
      "placeholder": "",
      "style": "IPY_MODEL_138722bc77c3400389ef616905904eaf",
      "value": "100%"
     }
    },
    "05c854c5dda546acabb9da4ddad5b0ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "138722bc77c3400389ef616905904eaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "163dbaf1211a44d39d2faf30e2509295": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1ccca095afed40f3a7d93abf2c94749b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "48f79cf624ea41229db24af7f7307eaa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_018f158461264820a43037233dc3843d",
       "IPY_MODEL_5ce0b73fc6f843138c8b76f290562c69",
       "IPY_MODEL_5d58cbdd7b944e99a9a24d2f7c9d3948"
      ],
      "layout": "IPY_MODEL_1ccca095afed40f3a7d93abf2c94749b"
     }
    },
    "5ce0b73fc6f843138c8b76f290562c69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7331c03842214571a355d32dc4f98865",
      "max": 400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_163dbaf1211a44d39d2faf30e2509295",
      "value": 400
     }
    },
    "5d58cbdd7b944e99a9a24d2f7c9d3948": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_843889c691d04f938ad4bfdf5a4f3a6b",
      "placeholder": "",
      "style": "IPY_MODEL_05c854c5dda546acabb9da4ddad5b0ce",
      "value": " 400/400 [04:11&lt;00:00,  1.69it/s]"
     }
    },
    "7331c03842214571a355d32dc4f98865": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "843889c691d04f938ad4bfdf5a4f3a6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90ee2656eb3e4bd5a0d1189cac2d521c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
